{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8970e3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dtale\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean, std\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198169a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ALEX\\Kaggle\\space_titanic\n",
      "C:\\ALEX\\Kaggle\\space_titanic\\..\\Spaceship Titanic\\space_titanic_data\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "dpath = os.path.join(os.getcwd(), \"..\\\\Spaceship Titanic\\\\space_titanic_data\")\n",
    "print(dpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a26dc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\ALEX\\\\Kaggle\\\\space_titanic\\\\..\\\\Spaceship Titanic\\\\space_titanic_data\\\\sample_submission.csv', 'C:\\\\ALEX\\\\Kaggle\\\\space_titanic\\\\..\\\\Spaceship Titanic\\\\space_titanic_data\\\\test.csv', 'C:\\\\ALEX\\\\Kaggle\\\\space_titanic\\\\..\\\\Spaceship Titanic\\\\space_titanic_data\\\\train.csv']\n"
     ]
    }
   ],
   "source": [
    "files1 = os.listdir(dpath)\n",
    "files2 = [os.path.join(dpath, f) for f in files1]\n",
    "files = [f for f in files2 if os.path.isfile(f)]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ba924",
   "metadata": {},
   "source": [
    "## Preprocess Functions\n",
    "\n",
    "### Transfer all to ONE HOT ENCODER and Cabin break down to 3 types of data\n",
    "### Missing cost values are set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df0a8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data_transform_rev1():\n",
    "    df_ = pd.read_csv(files[2])  # the training data\n",
    "    dft_ = transform_data(df_)\n",
    "    df_id = dft_.loc[:, dft_.columns == 'PassengerId']\n",
    "    dfd_ = dft_.loc[:, dft_.columns != 'PassengerId']  # passanger id should not be input for training\n",
    "    X = dfd_.loc[:, dfd_.columns != 'Transported']\n",
    "    Y = dfd_[['Transported']]    \n",
    "    return X, Y, df_id\n",
    "\n",
    "def get_train_data_transform_rev2():\n",
    "    df_ = pd.read_csv(files[2])  # the training data\n",
    "    dft_ = transform_data_rev2(df_)\n",
    "    df_id = dft_.loc[:, dft_.columns == 'PassengerId']\n",
    "    dfd_ = dft_.loc[:, dft_.columns != 'PassengerId']  # passanger id should not be input for training\n",
    "    X = dfd_.loc[:, dfd_.columns != 'Transported']\n",
    "    Y = dfd_[['Transported']]    \n",
    "    return X, Y, df_id\n",
    "\n",
    "def get_test_data_transform_rev1():\n",
    "    df_ = pd.read_csv(files[1])  # the test data\n",
    "    dft_ = transform_data(df_)\n",
    "    df_id = dft_.loc[:, dft_.columns == 'PassengerId']\n",
    "    X = dft_.loc[:, dft_.columns != 'PassengerId']  # passanger id should not be input for training\n",
    "    return X, df_id\n",
    "\n",
    "def get_test_data_transform_rev2():\n",
    "    df_ = pd.read_csv(files[1])  # the test data\n",
    "    dft_ = transform_data_rev2(df_)\n",
    "    df_id = dft_.loc[:, dft_.columns == 'PassengerId']\n",
    "    X = dft_.loc[:, dft_.columns != 'PassengerId']  # passanger id should not be input for training\n",
    "    return X, df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ece63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df_):\n",
    "    df = df_.copy()\n",
    "    \n",
    "    df['Home_Earth'] = df.apply(lambda row: 1 if row['HomePlanet'] == 'Earth' else 0, axis=1)\n",
    "    df['Home_Europa'] = df.apply(lambda row: 1 if row['HomePlanet'] == 'Europa' else 0, axis=1)\n",
    "    df['Home_Mars'] = df.apply(lambda row: 1 if row['HomePlanet'] == 'Mars' else 0, axis=1)\n",
    "    df['cryo_sleep_true'] = df.apply(lambda row: 1 if row['CryoSleep'] == True else 0, axis=1)\n",
    "    df['cryo_sleep_false'] = df.apply(lambda row: 1 if row['CryoSleep'] == False else 0, axis=1)    \n",
    "    df['destination_cancri'] = df.apply(lambda row: 1 if row['Destination'] == '55 Cancri e' else 0, axis=1)\n",
    "    df['destination_pso'] = df.apply(lambda row: 1 if row['Destination'] == 'PSO J318.5-22' else 0, axis=1)\n",
    "    df['destination_trappist'] = df.apply(lambda row: 1 if row['Destination'] == 'TRAPPIST-1e' else 0, axis=1)    \n",
    "    df['vip_true'] = df.apply(lambda row: 1 if row['VIP'] == True else 0, axis=1)\n",
    "    df['vip_false'] = df.apply(lambda row: 1 if row['VIP'] == False else 0, axis=1)    \n",
    "    \n",
    "    ccc = df['Cabin'].str.split(\"/\").values\n",
    "    c = [k[0] for k in ccc if type(k) == list]\n",
    "    cc = list(set(c))\n",
    "    cc.sort()\n",
    "    cc_d = {cc[i]:(i+1) for i in range(len(cc))}\n",
    "    s = [k[2] for k in ccc if type(k) == list]\n",
    "    ss = list(set(s))\n",
    "    ss.sort()\n",
    "    ss_d = {ss[i]:(i+1) for i in range(len(ss))}\n",
    "    df['cabin_row_'] = df.apply(lambda row: cc_d[row['Cabin'].split(\"/\")[0]] if type(row['Cabin']) == str else 0, axis=1)\n",
    "    m = max(df['cabin_row_'].values)\n",
    "    df['cabin_row'] = df['cabin_row_'] / m\n",
    "    df['cabin_t'] = df.apply(lambda row: 1 if type(row['Cabin']) == str and row['Cabin'].split(\"/\")[0] == 'T' else 0, axis=1)\n",
    "    df['cabin_num_'] = df.apply(lambda row: int(row['Cabin'].split(\"/\")[1]) if type(row['Cabin']) == str else 0, axis=1)\n",
    "    m = max(df['cabin_num_'].values)\n",
    "    df['cabin_num'] = df['cabin_num_'] / m\n",
    "    df['cabin_side_'] = df.apply(lambda row: ss_d[row['Cabin'].split(\"/\")[2]] if type(row['Cabin']) == str else 0, axis=1)    \n",
    "    m = max(df['cabin_side_'].values)\n",
    "    df['cabin_side'] = df['cabin_side_'] / m\n",
    "    df = df.drop(['cabin_row_', 'cabin_num_', 'cabin_side_'], axis=1)\n",
    "    \n",
    "    max_age = max(df['Age'].values)\n",
    "    df['age_norm'] = df.apply(lambda row: row['Age']/max_age if not pd.isnull(row['Age']) else 0, axis=1)    \n",
    "    dfc = df.drop(['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP'], axis=1)\n",
    "    \n",
    "    dfc['RoomService'].fillna(0, inplace=True)\n",
    "    dfc['roomservice'] = dfc['RoomService'] / max(dfc['RoomService'].values)\n",
    "    dfc['FoodCourt'].fillna(0, inplace=True)\n",
    "    dfc['foodcourt'] = dfc['FoodCourt'] / max(dfc['FoodCourt'].values)\n",
    "    dfc['ShoppingMall'].fillna(0, inplace=True)\n",
    "    dfc['shoppingmall'] = dfc['ShoppingMall'] / max(dfc['ShoppingMall'].values)\n",
    "    dfc['Spa'].fillna(0, inplace=True)\n",
    "    dfc['spa'] = dfc['Spa'] / max(dfc['Spa'].values)\n",
    "    dfc['VRDeck'].fillna(0, inplace=True)\n",
    "    dfc['vrdeck'] = dfc['VRDeck'] / max(dfc['VRDeck'].values)\n",
    "    dfc = dfc.drop(['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Name'], axis=1)\n",
    "    \n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd2d718",
   "metadata": {},
   "source": [
    "### Same as above but missing costs are imputed using KNN instead of set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136804f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_rev2(df_):\n",
    "    df = df_.copy()\n",
    "    \n",
    "    df['Home_Earth'] = df.apply(lambda row: 1 if row['HomePlanet'] == 'Earth' else 0, axis=1)\n",
    "    df['Home_Europa'] = df.apply(lambda row: 1 if row['HomePlanet'] == 'Europa' else 0, axis=1)\n",
    "    df['Home_Mars'] = df.apply(lambda row: 1 if row['HomePlanet'] == 'Mars' else 0, axis=1)\n",
    "    df['cryo_sleep_true'] = df.apply(lambda row: 1 if row['CryoSleep'] == True else 0, axis=1)\n",
    "    df['cryo_sleep_false'] = df.apply(lambda row: 1 if row['CryoSleep'] == False else 0, axis=1)    \n",
    "    df['destination_cancri'] = df.apply(lambda row: 1 if row['Destination'] == '55 Cancri e' else 0, axis=1)\n",
    "    df['destination_pso'] = df.apply(lambda row: 1 if row['Destination'] == 'PSO J318.5-22' else 0, axis=1)\n",
    "    df['destination_trappist'] = df.apply(lambda row: 1 if row['Destination'] == 'TRAPPIST-1e' else 0, axis=1)    \n",
    "    df['vip_true'] = df.apply(lambda row: 1 if row['VIP'] == True else 0, axis=1)\n",
    "    df['vip_false'] = df.apply(lambda row: 1 if row['VIP'] == False else 0, axis=1)    \n",
    "    \n",
    "    ccc = df['Cabin'].str.split(\"/\").values\n",
    "    c = [k[0] for k in ccc if type(k) == list]\n",
    "    cc = list(set(c))\n",
    "    cc.sort()\n",
    "    cc_d = {cc[i]:(i+1) for i in range(len(cc))}\n",
    "    s = [k[2] for k in ccc if type(k) == list]\n",
    "    ss = list(set(s))\n",
    "    ss.sort()\n",
    "    ss_d = {ss[i]:(i+1) for i in range(len(ss))}\n",
    "    df['cabin_row_'] = df.apply(lambda row: cc_d[row['Cabin'].split(\"/\")[0]] if type(row['Cabin']) == str else 0, axis=1)\n",
    "    m = max(df['cabin_row_'].values)\n",
    "    df['cabin_row'] = df['cabin_row_'] / m\n",
    "    df['cabin_t'] = df.apply(lambda row: 1 if type(row['Cabin']) == str and row['Cabin'].split(\"/\")[0] == 'T' else 0, axis=1)\n",
    "    df['cabin_num_'] = df.apply(lambda row: int(row['Cabin'].split(\"/\")[1]) if type(row['Cabin']) == str else 0, axis=1)\n",
    "    m = max(df['cabin_num_'].values)\n",
    "    df['cabin_num'] = df['cabin_num_'] / m\n",
    "    df['cabin_side_'] = df.apply(lambda row: ss_d[row['Cabin'].split(\"/\")[2]] if type(row['Cabin']) == str else 0, axis=1)    \n",
    "    m = max(df['cabin_side_'].values)\n",
    "    df['cabin_side'] = df['cabin_side_'] / m\n",
    "    df = df.drop(['cabin_row_', 'cabin_num_', 'cabin_side_'], axis=1)\n",
    "    \n",
    "    max_age = max(df['Age'].values)\n",
    "    df['age_norm'] = df.apply(lambda row: row['Age']/max_age if not pd.isnull(row['Age']) else 0, axis=1)    \n",
    "    dfc = df.drop(['HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP'], axis=1)\n",
    "    \n",
    "    X = dfc.loc[:, (dfc.columns != 'Transported') & (dfc.columns != 'PassengerId') & (dfc.columns != 'Name')]\n",
    "    xcols = list(X.columns)\n",
    "    if 'Transported' in list(dfc.columns):\n",
    "        Y = dfc[['Transported', 'PassengerId', 'Name']]\n",
    "    else:\n",
    "        Y = dfc[['PassengerId', 'Name']]\n",
    "        \n",
    "    imputer = KNNImputer()\n",
    "    imputer.fit(X)\n",
    "    Xtrans = imputer.transform(X)\n",
    "    xtrans_df = pd.DataFrame(data=Xtrans, columns=xcols)\n",
    "    dfc = pd.concat([xtrans_df, Y], axis=1)\n",
    "    dfc['RoomService'].fillna(0, inplace=True)\n",
    "    dfc['roomservice'] = dfc['RoomService'] / max(dfc['RoomService'].values)\n",
    "    dfc['FoodCourt'].fillna(0, inplace=True)\n",
    "    dfc['foodcourt'] = dfc['FoodCourt'] / max(dfc['FoodCourt'].values)\n",
    "    dfc['ShoppingMall'].fillna(0, inplace=True)\n",
    "    dfc['shoppingmall'] = dfc['ShoppingMall'] / max(dfc['ShoppingMall'].values)\n",
    "    dfc['Spa'].fillna(0, inplace=True)\n",
    "    dfc['spa'] = dfc['Spa'] / max(dfc['Spa'].values)\n",
    "    dfc['VRDeck'].fillna(0, inplace=True)\n",
    "    dfc['vrdeck'] = dfc['VRDeck'] / max(dfc['VRDeck'].values)\n",
    "    dfc = dfc.drop(['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Name'], axis=1)\n",
    "    \n",
    "    return dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902768da",
   "metadata": {},
   "source": [
    "# The Models - exploring models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2592825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7cbdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f5ca8",
   "metadata": {},
   "source": [
    "### The Data columns split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b039d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, df_id = get_train_data_transform_rev1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b99278",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e73270",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "model = XGBClassifier(n_estimators=65, num_parallel_tree=40)  # , num_parallel_tree=10)  #, n_jobs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b04e6e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary:logistic',\n",
       " 'use_label_encoder': None,\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded4454",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e134748",
   "metadata": {},
   "source": [
    "## Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a826db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140b5a5",
   "metadata": {},
   "source": [
    "## Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4650e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, Y2, df_id = get_train_data_transform_rev2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X2, Y2, test_size=test_size)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283517a5",
   "metadata": {},
   "source": [
    "## Train-Validate with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f049a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components =0.9)\n",
    "Xt = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X2, Y2, test_size=test_size)\n",
    "    pca = PCA()\n",
    "    Xt = pca.fit_transform(X_train)\n",
    "    model.fit(Xt, y_train)\n",
    "    Xt_test = pca.transform(X_test)\n",
    "    y_pred = model.predict(Xt_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3d6e9b",
   "metadata": {},
   "source": [
    "## Rev3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4e01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = IsolationForest(contamination=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44de8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc2 = transform_data_rev2(df)\n",
    "dfd2 = dfc2.loc[:, dfc2.columns != 'PassengerId']  # passanger id should not be input for training\n",
    "X2 = dfd2.loc[:, dfd2.columns != 'Transported']\n",
    "Y2 = dfd2[['Transported']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d78fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4439522",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train_, X_test, y_train_, y_test = train_test_split(X2, Y2, test_size=test_size)\n",
    "    \n",
    "    yhat = iso.fit_predict(X_train_)\n",
    "    mask = yhat != -1\n",
    "    X_train, y_train = X_train_.loc[mask, :], y_train_.loc[mask, :]\n",
    "#     print(f\"pre rows: {y_train_.shape} ;  post rows: {len(X_train)}\")\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65668193",
   "metadata": {},
   "source": [
    "#### Full Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74cd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = iso.fit_predict(X2)\n",
    "mask = yhat != -1\n",
    "X2_train, y2_train = X2.loc[mask, :], Y2.loc[mask, :]\n",
    "model.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb88543",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1, df_idt = get_train_data_transform_rev1()\n",
    "X2, Y2, df_idt = get_train_data_transform_rev2()\n",
    "X1_t, df_id = get_test_data_transform_rev1()\n",
    "X2_t, df_id = get_test_data_transform_rev2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b197b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = XGBClassifier(n_estimators=65, num_parallel_tree=40)  # , num_parallel_tree=10)  #, n_jobs=100)\n",
    "model2 = XGBClassifier(n_estimators=65, num_parallel_tree=40)  # , num_parallel_tree=10)  #, n_jobs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deac313",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X1, Y1)\n",
    "model2.fit(X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred1 = model1.predict(X1_t)\n",
    "y1_pred2 = model1.predict(X2_t)\n",
    "y2_pred1 = model2.predict(X1_t)\n",
    "y2_pred2 = model2.predict(X2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4510a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_df1 = pd.DataFrame(data=y1_pred1, columns=['Transported'])\n",
    "pred1_df1['Transported'] = pred1_df1['Transported'].astype(bool)\n",
    "\n",
    "pred1_df2 = pd.DataFrame(data=y1_pred2, columns=['Transported'])\n",
    "pred1_df2['Transported'] = pred1_df2['Transported'].astype(bool)\n",
    "\n",
    "pred2_df1 = pd.DataFrame(data=y2_pred1, columns=['Transported'])\n",
    "pred2_df1['Transported'] = pred2_df1['Transported'].astype(bool)\n",
    "\n",
    "pred2_df2 = pd.DataFrame(data=y2_pred2, columns=['Transported'])\n",
    "pred2_df2['Transported'] = pred2_df2['Transported'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfea789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_test1 = pd.concat([df_id, pred1_df1], axis=1)\n",
    "df1_test2 = pd.concat([df_id, pred1_df2], axis=1)\n",
    "df2_test1 = pd.concat([df_id, pred2_df1], axis=1)\n",
    "df2_test2 = pd.concat([df_id, pred2_df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc99e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_test1.to_csv(f\"xgboost11.csv\", index=False)\n",
    "df1_test2.to_csv(f\"xgboost12.csv\", index=False)\n",
    "df2_test1.to_csv(f\"xgboost21.csv\", index=False)\n",
    "df2_test2.to_csv(f\"xgboost22.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d91f40e",
   "metadata": {},
   "source": [
    "#  Models Predict\n",
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89ba798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_kn = BaggingClassifier(KNeighborsClassifier(), max_samples=0.5, max_features=0.5)\n",
    "bagging_kn = BaggingClassifier(DecisionTreeClassifier(), max_samples=0.5, max_features=0.5)\n",
    "bagging_ab = BaggingClassifier(AdaBoostClassifier(), max_samples=0.5, max_features=0.5)\n",
    "bagging_gb = BaggingClassifier(GradientBoostingClassifier(), max_samples=0.5, max_features=0.5)\n",
    "bagging_rf = BaggingClassifier(RandomForestClassifier(), max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e36a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators1 = [('K-Neighbors', bagging_kn), ('Decision-Trees', bagging_kn), ('AdaBoost', bagging_ab), \n",
    "               ('Grad-Boost', bagging_gb), ('Random-Forest', bagging_rf)]\n",
    "estimators2 = [('K-Neighbors', bagging_kn), ('Decision-Trees', bagging_kn), ('AdaBoost', bagging_ab), \n",
    "               ('Grad-Boost', bagging_gb), ('Random-Forest', bagging_rf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36abbf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49166595",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1, df_id = get_train_data_transform_rev1()\n",
    "X2, Y2, df_id = get_train_data_transform_rev2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5706a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=test_size)\n",
    "#     yhat = iso.fit_predict(X_train_)\n",
    "#     mask = yhat != -1\n",
    "#     X_train, y_train = X_train_.loc[mask, :], y_train_.loc[mask, :]\n",
    "    nn = []\n",
    "    for (name, estimator) in estimators1:\n",
    "        estimator.fit(X_train.values, y_train.values)\n",
    "        y_pred = estimator.predict(X_test.values)\n",
    "        accuracy = accuracy_score(y_test.values.reshape(len(y_test.values),), y_pred.reshape(len(y_pred),))\n",
    "        nn.append([name, round(accuracy * 100.0, 2)])\n",
    "    ss = [n[0]+\": \" + str(n[1]) + \"%\" for n in nn]\n",
    "    s = \"; \".join(ss)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925fb7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X2, Y2, test_size=test_size)\n",
    "    \n",
    "#     yhat = iso.fit_predict(X_train_)\n",
    "#     mask = yhat != -1\n",
    "#     X_train, y_train = X_train_.loc[mask, :], y_train_.loc[mask, :]\n",
    "    nn = []\n",
    "    for (name, estimator) in estimators2:\n",
    "        estimator.fit(X_train.values, y_train.values)\n",
    "        y_pred = estimator.predict(X_test.values)\n",
    "        accuracy = accuracy_score(y_test.values.reshape(len(y_test.values),), y_pred.reshape(len(y_pred),))\n",
    "        nn.append([name, round(accuracy * 100.0, 2)])\n",
    "    ss = [n[0]+\": \" + str(n[1]) + \"%\" for n in nn]\n",
    "    s = \"; \".join(ss)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637f2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test, df_id = get_test_data_transform_rev1()\n",
    "X2_test, df_id = get_test_data_transform_rev2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da834477",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dft = pd.read_csv(files[1])  # the test data\n",
    "dfct = transform_data(dft)\n",
    "pass_id = dfct[['PassengerId']]\n",
    "dfdt = dfct.loc[:, dfct.columns != 'PassengerId']  # passanger id should not be input for training\n",
    "X_test = dfdt\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465ef39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, estimator) in estimators1:\n",
    "    print(f\"Start fitting {name}.\")\n",
    "    estimator.fit(X1.values, Y1.values)\n",
    "    print(f\"Done fitting {name}, now starting prediction of test.\")\n",
    "    \n",
    "    y_pred = estimator.predict(X1_test.values)\n",
    "    print(f\"Done test prediction of {name}, now processing.\")\n",
    "    predictions = y_pred  # [round(value[0]) for value in y_pred]\n",
    "    pred_df = pd.DataFrame(data=predictions, columns=['Transported'])\n",
    "    pred_df['Transported'] = pred_df['Transported'].astype(bool)\n",
    "    df_test = pd.concat([df_id, pred_df], axis=1)\n",
    "    df_test.to_csv(f\"submit_test revb1_test1 {name}.csv\", index=False)\n",
    "\n",
    "    y_pred = estimator.predict(X2_test.values)\n",
    "    print(f\"Done test prediction of {name}, now processing.\")\n",
    "    predictions = y_pred  # [round(value[0]) for value in y_pred]\n",
    "    pred_df = pd.DataFrame(data=predictions, columns=['Transported'])\n",
    "    pred_df['Transported'] = pred_df['Transported'].astype(bool)\n",
    "    df_test = pd.concat([df_id, pred_df], axis=1)\n",
    "    df_test.to_csv(f\"submit_test revb1_test2 {name}.csv\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69396858",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, estimator) in estimators2:\n",
    "    print(f\"Start fitting {name}.\")\n",
    "    estimator.fit(X2.values, Y2.values)\n",
    "    print(f\"Done fitting {name}, now starting prediction of test.\")\n",
    "    \n",
    "    y_pred = estimator.predict(X1_test.values)\n",
    "    print(f\"Done test prediction of {name}, now processing.\")\n",
    "    predictions = y_pred  # [round(value[0]) for value in y_pred]\n",
    "    pred_df = pd.DataFrame(data=predictions, columns=['Transported'])\n",
    "    pred_df['Transported'] = pred_df['Transported'].astype(bool)\n",
    "    df_test = pd.concat([df_id, pred_df], axis=1)\n",
    "    df_test.to_csv(f\"submit_test revb2_test1 {name}.csv\", index=False)\n",
    "\n",
    "    y_pred = estimator.predict(X2_test.values)\n",
    "    print(f\"Done test prediction of {name}, now processing.\")\n",
    "    predictions = y_pred  # [round(value[0]) for value in y_pred]\n",
    "    pred_df = pd.DataFrame(data=predictions, columns=['Transported'])\n",
    "    pred_df['Transported'] = pred_df['Transported'].astype(bool)\n",
    "    df_test = pd.concat([df_id, pred_df], axis=1)\n",
    "    df_test.to_csv(f\"submit_test revb2_test2 {name}.csv\", index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49db888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft = pd.read_csv(files[1])  # the test data\n",
    "# dfct = transform_data(dft)\n",
    "# dfdt = dfct.loc[:, dfct.columns != 'PassengerId']  # passanger id should not be input for training\n",
    "# X2 = dfdt\n",
    "# print(len(X2))\n",
    "\n",
    "# y_pred = model2.predict(X2)\n",
    "# predictions = [round(value[0]) for value in y_pred]\n",
    "# len(predictions)\n",
    "\n",
    "# pass_id = dfct[['PassengerId']]\n",
    "# pred_df = pd.DataFrame(data=predictions, columns=['Transported'])\n",
    "# pred_df['Transported'] = pred_df['Transported'].astype(bool)\n",
    "# df_test = pd.concat([pass_id, pred_df], axis=1)\n",
    "\n",
    "# df_test.to_csv('submit_test rev6 nn full train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b4b058",
   "metadata": {},
   "source": [
    "## NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddb6e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.constraints import MaxNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a641b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_in = Input(shape=(20,))\n",
    "# x1 = Dense(64)(x_in)\n",
    "# x2 = Dense(32)(x1)\n",
    "# x3 = Dense(16)(x2)\n",
    "# x_out = Dense(1)(x3)\n",
    "# model = Model(inputs=x_in, outputs=x_out)\n",
    "\n",
    "nn_model = tf.keras.Sequential()\n",
    "nn_model.add(Dropout(0.2, input_shape=(20,)))\n",
    "nn_model.add(Dense(64, activation='relu', kernel_initializer='he_normal', kernel_constraint=MaxNorm(3)))\n",
    "nn_model.add(Dropout(0.2))\n",
    "nn_model.add(Dense(32, activation='relu', kernel_initializer='he_normal', kernel_constraint=MaxNorm(3)))\n",
    "nn_model.add(Dense(16, activation='relu', kernel_initializer='he_normal', kernel_constraint=MaxNorm(3)))\n",
    "nn_model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "nn_model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-3), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0a26bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model3 = tf.keras.Sequential()\n",
    "nn_model3.add(Dense(64, activation='relu', kernel_initializer='he_normal', input_shape=(20,), kernel_constraint=MaxNorm(3)))\n",
    "nn_model3.add(Dropout(0.2))\n",
    "nn_model3.add(Dense(32, activation='relu', kernel_initializer='he_normal', kernel_constraint=MaxNorm(3)))\n",
    "nn_model3.add(Dropout(0.2))\n",
    "nn_model3.add(Dense(16, activation='relu', kernel_initializer='he_normal', kernel_constraint=MaxNorm(3)))\n",
    "nn_model3.add(Dropout(0.1))\n",
    "nn_model3.add(Dense(8, activation='relu', kernel_initializer='he_normal', kernel_constraint=MaxNorm(3)))\n",
    "nn_model3.add(Dropout(0.05))\n",
    "nn_model3.add(Dense(1, activation='sigmoid'))\n",
    "nn_model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-3), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model1 = tf.keras.Sequential()\n",
    "nn_model1.add(Dense(64, activation='relu', kernel_initializer='he_normal', input_shape=(20,)))\n",
    "nn_model1.add(Dense(32, activation='relu', kernel_initializer='he_normal'))\n",
    "nn_model1.add(Dense(16, activation='relu', kernel_initializer='he_normal'))\n",
    "nn_model1.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "nn_model1.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "nn_model1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-4), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model2 = tf.keras.Sequential()\n",
    "nn_model2.add(Dense(64, activation='relu', kernel_initializer='he_normal', input_shape=(20,)))\n",
    "nn_model2.add(Dense(32, activation='relu', kernel_initializer='he_normal'))\n",
    "nn_model2.add(Dense(16, activation='relu', kernel_initializer='he_normal'))\n",
    "nn_model2.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "nn_model2.add(Dense(1, activation='sigmoid'))\n",
    "nn_model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-4), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9dacca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1, df_id = get_train_data_transform_rev1()\n",
    "X2, Y2, df_id = get_train_data_transform_rev2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "057fcbe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "272/272 [==============================] - 1s 1ms/step - loss: 0.6319 - accuracy: 0.6932\n",
      "Epoch 2/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5470 - accuracy: 0.7279\n",
      "Epoch 3/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.7453\n",
      "Epoch 4/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7508\n",
      "Epoch 5/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7591\n",
      "Epoch 6/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7595\n",
      "Epoch 7/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7668\n",
      "Epoch 8/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7625\n",
      "Epoch 9/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7651\n",
      "Epoch 10/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7715\n",
      "Epoch 11/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7730\n",
      "Epoch 12/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7672\n",
      "Epoch 13/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7704\n",
      "Epoch 14/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7725\n",
      "Epoch 15/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7660\n",
      "Epoch 16/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7710\n",
      "Epoch 17/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7750\n",
      "Epoch 18/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7776\n",
      "Epoch 19/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7680\n",
      "Epoch 20/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7730\n",
      "Epoch 21/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7782\n",
      "Epoch 22/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7769\n",
      "Epoch 23/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7763\n",
      "Epoch 24/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7784\n",
      "Epoch 25/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7744\n",
      "Epoch 26/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7761\n",
      "Epoch 27/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7744\n",
      "Epoch 28/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7789\n",
      "Epoch 29/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7726\n",
      "Epoch 30/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7832\n",
      "Epoch 31/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7806\n",
      "Epoch 32/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7843\n",
      "Epoch 33/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7782\n",
      "Epoch 34/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7797\n",
      "Epoch 35/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7786\n",
      "Epoch 36/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7845\n",
      "Epoch 37/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7811\n",
      "Epoch 38/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7824\n",
      "Epoch 39/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7842\n",
      "Epoch 40/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7814\n",
      "Epoch 41/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7795\n",
      "Epoch 42/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7857\n",
      "Epoch 43/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.7807\n",
      "Epoch 44/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7833\n",
      "Epoch 45/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7788\n",
      "Epoch 46/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7766\n",
      "Epoch 47/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7825\n",
      "Epoch 48/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7847\n",
      "Epoch 49/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7834\n",
      "Epoch 50/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7824\n",
      "Epoch 51/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7798\n",
      "Epoch 52/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4420 - accuracy: 0.7870\n",
      "Epoch 53/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7827\n",
      "Epoch 54/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7837\n",
      "Epoch 55/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7824\n",
      "Epoch 56/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7805\n",
      "Epoch 57/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7786\n",
      "Epoch 58/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7858\n",
      "Epoch 59/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7828\n",
      "Epoch 60/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7826\n",
      "Epoch 61/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.7835\n",
      "Epoch 62/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7811\n",
      "Epoch 63/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7870\n",
      "Epoch 64/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7801\n",
      "Epoch 65/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7809\n",
      "Epoch 66/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7834\n",
      "Epoch 67/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7807\n",
      "Epoch 68/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7827\n",
      "Epoch 69/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7820\n",
      "Epoch 70/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7801\n",
      "Epoch 71/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7830\n",
      "Epoch 72/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7801\n",
      "Epoch 73/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7809\n",
      "Epoch 74/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.7813\n",
      "Epoch 75/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7787\n",
      "Epoch 76/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7841\n",
      "Epoch 77/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7845\n",
      "Epoch 78/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7840\n",
      "Epoch 79/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.7833\n",
      "Epoch 80/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7799\n",
      "Epoch 81/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7833\n",
      "Epoch 82/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7848\n",
      "Epoch 83/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7805\n",
      "Epoch 84/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7809\n",
      "Epoch 85/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.7861\n",
      "Epoch 86/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7849\n",
      "Epoch 87/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7861\n",
      "Epoch 88/800\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7903\n",
      "Epoch 89/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7806\n",
      "Epoch 90/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7817\n",
      "Epoch 91/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7838\n",
      "Epoch 92/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7819\n",
      "Epoch 93/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7855\n",
      "Epoch 94/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7745\n",
      "Epoch 95/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7827\n",
      "Epoch 96/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7857\n",
      "Epoch 97/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.7850\n",
      "Epoch 98/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.7827\n",
      "Epoch 99/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7830\n",
      "Epoch 100/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7838\n",
      "Epoch 101/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7807\n",
      "Epoch 102/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7766\n",
      "Epoch 103/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7835\n",
      "Epoch 104/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7813\n",
      "Epoch 105/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.7841\n",
      "Epoch 106/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7805\n",
      "Epoch 107/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7874\n",
      "Epoch 108/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7796\n",
      "Epoch 109/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7809\n",
      "Epoch 110/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7843\n",
      "Epoch 111/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.7855\n",
      "Epoch 112/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7894\n",
      "Epoch 113/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7847\n",
      "Epoch 114/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7827\n",
      "Epoch 115/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7834\n",
      "Epoch 116/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7775\n",
      "Epoch 117/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7847\n",
      "Epoch 118/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4426 - accuracy: 0.7814\n",
      "Epoch 119/800\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.4406 - accuracy: 0.7838\n",
      "Epoch 120/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7873\n",
      "Epoch 121/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7848\n",
      "Epoch 122/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7861\n",
      "Epoch 123/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7806\n",
      "Epoch 124/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7817\n",
      "Epoch 125/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.7815\n",
      "Epoch 126/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7866\n",
      "Epoch 127/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7847\n",
      "Epoch 128/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7828\n",
      "Epoch 129/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7836\n",
      "Epoch 130/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7882\n",
      "Epoch 131/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7833\n",
      "Epoch 132/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7811\n",
      "Epoch 133/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7824\n",
      "Epoch 134/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7888\n",
      "Epoch 135/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7803\n",
      "Epoch 136/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7898\n",
      "Epoch 137/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7898\n",
      "Epoch 138/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7829\n",
      "Epoch 139/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7857\n",
      "Epoch 140/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7775\n",
      "Epoch 141/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7851\n",
      "Epoch 142/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7829\n",
      "Epoch 143/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7851\n",
      "Epoch 144/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7861\n",
      "Epoch 145/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7890\n",
      "Epoch 146/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7845\n",
      "Epoch 147/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7804\n",
      "Epoch 148/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.7807\n",
      "Epoch 149/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7840\n",
      "Epoch 150/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7818\n",
      "Epoch 151/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7845\n",
      "Epoch 152/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4382 - accuracy: 0.7802\n",
      "Epoch 153/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7849\n",
      "Epoch 154/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7882\n",
      "Epoch 155/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4405 - accuracy: 0.7822\n",
      "Epoch 156/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7848\n",
      "Epoch 157/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7832\n",
      "Epoch 158/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7885\n",
      "Epoch 159/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7879\n",
      "Epoch 160/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7821\n",
      "Epoch 161/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7855\n",
      "Epoch 162/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7850\n",
      "Epoch 163/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7844\n",
      "Epoch 164/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7815\n",
      "Epoch 165/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7833\n",
      "Epoch 166/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7859\n",
      "Epoch 167/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7834\n",
      "Epoch 168/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7826\n",
      "Epoch 169/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7872\n",
      "Epoch 170/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7834\n",
      "Epoch 171/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7825\n",
      "Epoch 172/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7879\n",
      "Epoch 173/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7872\n",
      "Epoch 174/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7821\n",
      "Epoch 175/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7848\n",
      "Epoch 176/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7844\n",
      "Epoch 177/800\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.4331 - accuracy: 0.7871\n",
      "Epoch 178/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7841\n",
      "Epoch 179/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.7870\n",
      "Epoch 180/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7864\n",
      "Epoch 181/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7847\n",
      "Epoch 182/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4423 - accuracy: 0.7812\n",
      "Epoch 183/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4407 - accuracy: 0.7792\n",
      "Epoch 184/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7832\n",
      "Epoch 185/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7855\n",
      "Epoch 186/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7852\n",
      "Epoch 187/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7870\n",
      "Epoch 188/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7870\n",
      "Epoch 189/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7806\n",
      "Epoch 190/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7830\n",
      "Epoch 191/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7882\n",
      "Epoch 192/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7840\n",
      "Epoch 193/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7894\n",
      "Epoch 194/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7840\n",
      "Epoch 195/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7842\n",
      "Epoch 196/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7849\n",
      "Epoch 197/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7809\n",
      "Epoch 198/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7895\n",
      "Epoch 199/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7873\n",
      "Epoch 200/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7838\n",
      "Epoch 201/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.7847\n",
      "Epoch 202/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7843\n",
      "Epoch 203/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7848\n",
      "Epoch 204/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7886\n",
      "Epoch 205/800\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.4302 - accuracy: 0.7895\n",
      "Epoch 206/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7841\n",
      "Epoch 207/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7899\n",
      "Epoch 208/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7827\n",
      "Epoch 209/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7834\n",
      "Epoch 210/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7876\n",
      "Epoch 211/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7893\n",
      "Epoch 212/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7842\n",
      "Epoch 213/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7804\n",
      "Epoch 214/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7844\n",
      "Epoch 215/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7891\n",
      "Epoch 216/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7880\n",
      "Epoch 217/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7866\n",
      "Epoch 218/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7861\n",
      "Epoch 219/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7858\n",
      "Epoch 220/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7835\n",
      "Epoch 221/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7833\n",
      "Epoch 222/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7896\n",
      "Epoch 223/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7894\n",
      "Epoch 224/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7840\n",
      "Epoch 225/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7798\n",
      "Epoch 226/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7853\n",
      "Epoch 227/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7811\n",
      "Epoch 228/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7897\n",
      "Epoch 229/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7856\n",
      "Epoch 230/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7828\n",
      "Epoch 231/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7821\n",
      "Epoch 232/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7840\n",
      "Epoch 233/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7880\n",
      "Epoch 234/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7871\n",
      "Epoch 235/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7885\n",
      "Epoch 236/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7890\n",
      "Epoch 237/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7887\n",
      "Epoch 238/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7824\n",
      "Epoch 239/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7837\n",
      "Epoch 240/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7810\n",
      "Epoch 241/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7886\n",
      "Epoch 242/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7921\n",
      "Epoch 243/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7872\n",
      "Epoch 244/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7822\n",
      "Epoch 245/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7837\n",
      "Epoch 246/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7827\n",
      "Epoch 247/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7885\n",
      "Epoch 248/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7838\n",
      "Epoch 249/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7842\n",
      "Epoch 250/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7896\n",
      "Epoch 251/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7864\n",
      "Epoch 252/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7858\n",
      "Epoch 253/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7897\n",
      "Epoch 254/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7851\n",
      "Epoch 255/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7906\n",
      "Epoch 256/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7874\n",
      "Epoch 257/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7822\n",
      "Epoch 258/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7807\n",
      "Epoch 259/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7835\n",
      "Epoch 260/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7833\n",
      "Epoch 261/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7821\n",
      "Epoch 262/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7805\n",
      "Epoch 263/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7864\n",
      "Epoch 264/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7822\n",
      "Epoch 265/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7826\n",
      "Epoch 266/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7840\n",
      "Epoch 267/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7913\n",
      "Epoch 268/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7836\n",
      "Epoch 269/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7898\n",
      "Epoch 270/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7829\n",
      "Epoch 271/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7855\n",
      "Epoch 272/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7842\n",
      "Epoch 273/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7879\n",
      "Epoch 274/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7818\n",
      "Epoch 275/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7878\n",
      "Epoch 276/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7827\n",
      "Epoch 277/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7864\n",
      "Epoch 278/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.7811\n",
      "Epoch 279/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7837\n",
      "Epoch 280/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7898\n",
      "Epoch 281/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7865\n",
      "Epoch 282/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7781\n",
      "Epoch 283/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7815\n",
      "Epoch 284/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7898\n",
      "Epoch 285/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7817\n",
      "Epoch 286/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7887\n",
      "Epoch 287/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7805\n",
      "Epoch 288/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7897\n",
      "Epoch 289/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7849\n",
      "Epoch 290/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7799\n",
      "Epoch 291/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7909\n",
      "Epoch 292/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7840\n",
      "Epoch 293/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7828\n",
      "Epoch 294/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7834\n",
      "Epoch 295/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7920\n",
      "Epoch 296/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7889\n",
      "Epoch 297/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7859\n",
      "Epoch 298/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7893\n",
      "Epoch 299/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7826\n",
      "Epoch 300/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7819\n",
      "Epoch 301/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7789\n",
      "Epoch 302/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7916\n",
      "Epoch 303/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7826\n",
      "Epoch 304/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7853\n",
      "Epoch 305/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7893\n",
      "Epoch 306/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7864\n",
      "Epoch 307/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7913\n",
      "Epoch 308/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7882\n",
      "Epoch 309/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7903\n",
      "Epoch 310/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7825\n",
      "Epoch 311/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7866\n",
      "Epoch 312/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7860\n",
      "Epoch 313/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7843\n",
      "Epoch 314/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7849\n",
      "Epoch 315/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7851\n",
      "Epoch 316/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7866\n",
      "Epoch 317/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7908\n",
      "Epoch 318/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7838\n",
      "Epoch 319/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7880\n",
      "Epoch 320/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7867\n",
      "Epoch 321/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7836\n",
      "Epoch 322/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7887\n",
      "Epoch 323/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7848\n",
      "Epoch 324/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7890\n",
      "Epoch 325/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7903\n",
      "Epoch 326/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7873\n",
      "Epoch 327/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7860\n",
      "Epoch 328/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7855\n",
      "Epoch 329/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4245 - accuracy: 0.7905\n",
      "Epoch 330/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7896\n",
      "Epoch 331/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7881\n",
      "Epoch 332/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7859\n",
      "Epoch 333/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7805\n",
      "Epoch 334/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7837\n",
      "Epoch 335/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7865\n",
      "Epoch 336/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.7882\n",
      "Epoch 337/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7860\n",
      "Epoch 338/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7881\n",
      "Epoch 339/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7902\n",
      "Epoch 340/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7833\n",
      "Epoch 341/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7929\n",
      "Epoch 342/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7852\n",
      "Epoch 343/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7796\n",
      "Epoch 344/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7859\n",
      "Epoch 345/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7906\n",
      "Epoch 346/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7849\n",
      "Epoch 347/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7866\n",
      "Epoch 348/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7872\n",
      "Epoch 349/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7866\n",
      "Epoch 350/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7807\n",
      "Epoch 351/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7866\n",
      "Epoch 352/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4255 - accuracy: 0.7897\n",
      "Epoch 353/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7867\n",
      "Epoch 354/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7851\n",
      "Epoch 355/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7837\n",
      "Epoch 356/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7888\n",
      "Epoch 357/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7851\n",
      "Epoch 358/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7894\n",
      "Epoch 359/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7783\n",
      "Epoch 360/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7835\n",
      "Epoch 361/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7845\n",
      "Epoch 362/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7845\n",
      "Epoch 363/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7829\n",
      "Epoch 364/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7822\n",
      "Epoch 365/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.7896\n",
      "Epoch 366/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7887\n",
      "Epoch 367/800\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.7870\n",
      "Epoch 368/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7894\n",
      "Epoch 369/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7818\n",
      "Epoch 370/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7874\n",
      "Epoch 371/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7836\n",
      "Epoch 372/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7887\n",
      "Epoch 373/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.7942\n",
      "Epoch 374/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7825\n",
      "Epoch 375/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7776\n",
      "Epoch 376/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7843\n",
      "Epoch 377/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7883\n",
      "Epoch 378/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7826\n",
      "Epoch 379/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7794\n",
      "Epoch 380/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.7827\n",
      "Epoch 381/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7825\n",
      "Epoch 382/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7792\n",
      "Epoch 383/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7836\n",
      "Epoch 384/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7841\n",
      "Epoch 385/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7837\n",
      "Epoch 386/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7817\n",
      "Epoch 387/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7829\n",
      "Epoch 388/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7843\n",
      "Epoch 389/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7818\n",
      "Epoch 390/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7834\n",
      "Epoch 391/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7817\n",
      "Epoch 392/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7859\n",
      "Epoch 393/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7874\n",
      "Epoch 394/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7826\n",
      "Epoch 395/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7888\n",
      "Epoch 396/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7786\n",
      "Epoch 397/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4395 - accuracy: 0.7814\n",
      "Epoch 398/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7840\n",
      "Epoch 399/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7920\n",
      "Epoch 400/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7824\n",
      "Epoch 401/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7826\n",
      "Epoch 402/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7871\n",
      "Epoch 403/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7876\n",
      "Epoch 404/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7867\n",
      "Epoch 405/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7873\n",
      "Epoch 406/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7844\n",
      "Epoch 407/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7841\n",
      "Epoch 408/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7896\n",
      "Epoch 409/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7870\n",
      "Epoch 410/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7832\n",
      "Epoch 411/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7837\n",
      "Epoch 412/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4422 - accuracy: 0.7825\n",
      "Epoch 413/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7852\n",
      "Epoch 414/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7893\n",
      "Epoch 415/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7874\n",
      "Epoch 416/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7850\n",
      "Epoch 417/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7897\n",
      "Epoch 418/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.7855\n",
      "Epoch 419/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7797\n",
      "Epoch 420/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7830\n",
      "Epoch 421/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7853\n",
      "Epoch 422/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7867\n",
      "Epoch 423/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7912\n",
      "Epoch 424/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7850\n",
      "Epoch 425/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.7908\n",
      "Epoch 426/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7890\n",
      "Epoch 427/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7850\n",
      "Epoch 428/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7825\n",
      "Epoch 429/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7845\n",
      "Epoch 430/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7842\n",
      "Epoch 431/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7840\n",
      "Epoch 432/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7864\n",
      "Epoch 433/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7872\n",
      "Epoch 434/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7847\n",
      "Epoch 435/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7871\n",
      "Epoch 436/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7824\n",
      "Epoch 437/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7855\n",
      "Epoch 438/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7867\n",
      "Epoch 439/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7847\n",
      "Epoch 440/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7876\n",
      "Epoch 441/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7827\n",
      "Epoch 442/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7904\n",
      "Epoch 443/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7881\n",
      "Epoch 444/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7824\n",
      "Epoch 445/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7841\n",
      "Epoch 446/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7805\n",
      "Epoch 447/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7830\n",
      "Epoch 448/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7813\n",
      "Epoch 449/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7888\n",
      "Epoch 450/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7874\n",
      "Epoch 451/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7840\n",
      "Epoch 452/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7818\n",
      "Epoch 453/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7851\n",
      "Epoch 454/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7824\n",
      "Epoch 455/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7832\n",
      "Epoch 456/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7838\n",
      "Epoch 457/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7872\n",
      "Epoch 458/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7867\n",
      "Epoch 459/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7850\n",
      "Epoch 460/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7868\n",
      "Epoch 461/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7851\n",
      "Epoch 462/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7886\n",
      "Epoch 463/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7873\n",
      "Epoch 464/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7888\n",
      "Epoch 465/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7835\n",
      "Epoch 466/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7848\n",
      "Epoch 467/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7876\n",
      "Epoch 468/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7890\n",
      "Epoch 469/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7825\n",
      "Epoch 470/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7858\n",
      "Epoch 471/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7865\n",
      "Epoch 472/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7853\n",
      "Epoch 473/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.7809\n",
      "Epoch 474/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4253 - accuracy: 0.7918\n",
      "Epoch 475/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7838\n",
      "Epoch 476/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7863\n",
      "Epoch 477/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7908\n",
      "Epoch 478/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7865\n",
      "Epoch 479/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7832\n",
      "Epoch 480/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7812\n",
      "Epoch 481/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7868\n",
      "Epoch 482/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.7870\n",
      "Epoch 483/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7873\n",
      "Epoch 484/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7817\n",
      "Epoch 485/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4357 - accuracy: 0.7873\n",
      "Epoch 486/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7856\n",
      "Epoch 487/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7883\n",
      "Epoch 488/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4393 - accuracy: 0.7830\n",
      "Epoch 489/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4380 - accuracy: 0.7889\n",
      "Epoch 490/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7879\n",
      "Epoch 491/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7865\n",
      "Epoch 492/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7868\n",
      "Epoch 493/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7909\n",
      "Epoch 494/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7821\n",
      "Epoch 495/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7865\n",
      "Epoch 496/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7852\n",
      "Epoch 497/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7853\n",
      "Epoch 498/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7883\n",
      "Epoch 499/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7868\n",
      "Epoch 500/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4408 - accuracy: 0.7752\n",
      "Epoch 501/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7863\n",
      "Epoch 502/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7883\n",
      "Epoch 503/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7865\n",
      "Epoch 504/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.7857\n",
      "Epoch 505/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7853\n",
      "Epoch 506/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7898\n",
      "Epoch 507/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7859\n",
      "Epoch 508/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7886\n",
      "Epoch 509/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7861\n",
      "Epoch 510/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7872\n",
      "Epoch 511/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7852\n",
      "Epoch 512/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.7830\n",
      "Epoch 513/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7885\n",
      "Epoch 514/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7842\n",
      "Epoch 515/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7844\n",
      "Epoch 516/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7858\n",
      "Epoch 517/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7894\n",
      "Epoch 518/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7830\n",
      "Epoch 519/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.7889\n",
      "Epoch 520/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7802\n",
      "Epoch 521/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7870\n",
      "Epoch 522/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7863\n",
      "Epoch 523/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4373 - accuracy: 0.7821\n",
      "Epoch 524/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7849\n",
      "Epoch 525/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7853\n",
      "Epoch 526/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7871\n",
      "Epoch 527/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7871\n",
      "Epoch 528/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7871\n",
      "Epoch 529/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.7864\n",
      "Epoch 530/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7926\n",
      "Epoch 531/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7841\n",
      "Epoch 532/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.7921\n",
      "Epoch 533/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7875\n",
      "Epoch 534/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7857\n",
      "Epoch 535/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7856\n",
      "Epoch 536/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7867\n",
      "Epoch 537/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7828\n",
      "Epoch 538/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7926\n",
      "Epoch 539/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7844\n",
      "Epoch 540/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7852\n",
      "Epoch 541/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7890\n",
      "Epoch 542/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7899\n",
      "Epoch 543/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7878\n",
      "Epoch 544/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7896\n",
      "Epoch 545/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7874\n",
      "Epoch 546/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7875\n",
      "Epoch 547/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7851\n",
      "Epoch 548/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7908\n",
      "Epoch 549/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7822\n",
      "Epoch 550/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7897\n",
      "Epoch 551/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7833\n",
      "Epoch 552/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7874\n",
      "Epoch 553/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7890\n",
      "Epoch 554/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7860\n",
      "Epoch 555/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7809\n",
      "Epoch 556/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7861\n",
      "Epoch 557/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7896\n",
      "Epoch 558/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7885\n",
      "Epoch 559/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7890\n",
      "Epoch 560/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4252 - accuracy: 0.7950\n",
      "Epoch 561/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7836\n",
      "Epoch 562/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7850\n",
      "Epoch 563/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7902\n",
      "Epoch 564/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7858\n",
      "Epoch 565/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7867\n",
      "Epoch 566/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7814\n",
      "Epoch 567/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7848\n",
      "Epoch 568/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7880\n",
      "Epoch 569/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7875\n",
      "Epoch 570/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7914\n",
      "Epoch 571/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7880\n",
      "Epoch 572/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.7867\n",
      "Epoch 573/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7841\n",
      "Epoch 574/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7851\n",
      "Epoch 575/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7858\n",
      "Epoch 576/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7847\n",
      "Epoch 577/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7922\n",
      "Epoch 578/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7873\n",
      "Epoch 579/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7837\n",
      "Epoch 580/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7812\n",
      "Epoch 581/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7859\n",
      "Epoch 582/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7853\n",
      "Epoch 583/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7883\n",
      "Epoch 584/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7893\n",
      "Epoch 585/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7861\n",
      "Epoch 586/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7857\n",
      "Epoch 587/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7852\n",
      "Epoch 588/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7876\n",
      "Epoch 589/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7948\n",
      "Epoch 590/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7891\n",
      "Epoch 591/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7866\n",
      "Epoch 592/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7873\n",
      "Epoch 593/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7836\n",
      "Epoch 594/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7906\n",
      "Epoch 595/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7834\n",
      "Epoch 596/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7904\n",
      "Epoch 597/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7840\n",
      "Epoch 598/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7885\n",
      "Epoch 599/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7893\n",
      "Epoch 600/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7879\n",
      "Epoch 601/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7880\n",
      "Epoch 602/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7843\n",
      "Epoch 603/800\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.4312 - accuracy: 0.7860\n",
      "Epoch 604/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7875\n",
      "Epoch 605/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7802\n",
      "Epoch 606/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.7860\n",
      "Epoch 607/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7835\n",
      "Epoch 608/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7814\n",
      "Epoch 609/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7885\n",
      "Epoch 610/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7824\n",
      "Epoch 611/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7864\n",
      "Epoch 612/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7852\n",
      "Epoch 613/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7835\n",
      "Epoch 614/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7836\n",
      "Epoch 615/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7824\n",
      "Epoch 616/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4226 - accuracy: 0.7910\n",
      "Epoch 617/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7902\n",
      "Epoch 618/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7876\n",
      "Epoch 619/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7918\n",
      "Epoch 620/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7850\n",
      "Epoch 621/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4343 - accuracy: 0.7820\n",
      "Epoch 622/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7882\n",
      "Epoch 623/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4328 - accuracy: 0.7843\n",
      "Epoch 624/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7856\n",
      "Epoch 625/800\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.4295 - accuracy: 0.7865\n",
      "Epoch 626/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7859\n",
      "Epoch 627/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7805\n",
      "Epoch 628/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7873\n",
      "Epoch 629/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7857\n",
      "Epoch 630/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7897\n",
      "Epoch 631/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7814\n",
      "Epoch 632/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7807\n",
      "Epoch 633/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7870\n",
      "Epoch 634/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4345 - accuracy: 0.7843\n",
      "Epoch 635/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7857\n",
      "Epoch 636/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7824\n",
      "Epoch 637/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7838\n",
      "Epoch 638/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7848\n",
      "Epoch 639/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7856\n",
      "Epoch 640/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7893\n",
      "Epoch 641/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7830\n",
      "Epoch 642/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7904\n",
      "Epoch 643/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7849\n",
      "Epoch 644/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7792\n",
      "Epoch 645/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7897\n",
      "Epoch 646/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7879\n",
      "Epoch 647/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7871\n",
      "Epoch 648/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4249 - accuracy: 0.7898\n",
      "Epoch 649/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7845\n",
      "Epoch 650/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7870\n",
      "Epoch 651/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7870\n",
      "Epoch 652/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7870\n",
      "Epoch 653/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7867\n",
      "Epoch 654/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7821\n",
      "Epoch 655/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7847\n",
      "Epoch 656/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7850\n",
      "Epoch 657/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7859\n",
      "Epoch 658/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4367 - accuracy: 0.7810\n",
      "Epoch 659/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7860\n",
      "Epoch 660/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7848\n",
      "Epoch 661/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7888\n",
      "Epoch 662/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7817\n",
      "Epoch 663/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7872\n",
      "Epoch 664/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7857\n",
      "Epoch 665/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7835\n",
      "Epoch 666/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7860\n",
      "Epoch 667/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7865\n",
      "Epoch 668/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7883\n",
      "Epoch 669/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7858\n",
      "Epoch 670/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7872\n",
      "Epoch 671/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7906\n",
      "Epoch 672/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7861\n",
      "Epoch 673/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7860\n",
      "Epoch 674/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7870\n",
      "Epoch 675/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.7883\n",
      "Epoch 676/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7880\n",
      "Epoch 677/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.7835\n",
      "Epoch 678/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7829\n",
      "Epoch 679/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7887\n",
      "Epoch 680/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7845\n",
      "Epoch 681/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7842\n",
      "Epoch 682/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.7796\n",
      "Epoch 683/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7920\n",
      "Epoch 684/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7888\n",
      "Epoch 685/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4385 - accuracy: 0.7827\n",
      "Epoch 686/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7890\n",
      "Epoch 687/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.7859\n",
      "Epoch 688/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7873\n",
      "Epoch 689/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7817\n",
      "Epoch 690/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7826\n",
      "Epoch 691/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7864\n",
      "Epoch 692/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.7844\n",
      "Epoch 693/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.7844\n",
      "Epoch 694/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7921\n",
      "Epoch 695/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7874\n",
      "Epoch 696/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7826\n",
      "Epoch 697/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7803\n",
      "Epoch 698/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4360 - accuracy: 0.7797\n",
      "Epoch 699/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7876\n",
      "Epoch 700/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4362 - accuracy: 0.7801\n",
      "Epoch 701/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7826\n",
      "Epoch 702/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7840\n",
      "Epoch 703/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7888\n",
      "Epoch 704/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7837\n",
      "Epoch 705/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7882\n",
      "Epoch 706/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7832\n",
      "Epoch 707/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7879\n",
      "Epoch 708/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7886\n",
      "Epoch 709/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7885\n",
      "Epoch 710/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7859\n",
      "Epoch 711/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7863\n",
      "Epoch 712/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7861\n",
      "Epoch 713/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7882\n",
      "Epoch 714/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7832\n",
      "Epoch 715/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7860\n",
      "Epoch 716/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7868\n",
      "Epoch 717/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7888\n",
      "Epoch 718/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7868\n",
      "Epoch 719/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7852\n",
      "Epoch 720/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7883\n",
      "Epoch 721/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.7896\n",
      "Epoch 722/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7847\n",
      "Epoch 723/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7848\n",
      "Epoch 724/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7843\n",
      "Epoch 725/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4238 - accuracy: 0.7902\n",
      "Epoch 726/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7879\n",
      "Epoch 727/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7863\n",
      "Epoch 728/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7845\n",
      "Epoch 729/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.7871\n",
      "Epoch 730/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7859\n",
      "Epoch 731/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7880\n",
      "Epoch 732/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7824\n",
      "Epoch 733/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4315 - accuracy: 0.7882\n",
      "Epoch 734/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7895\n",
      "Epoch 735/800\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.4245 - accuracy: 0.7922\n",
      "Epoch 736/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7872\n",
      "Epoch 737/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7842\n",
      "Epoch 738/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7911\n",
      "Epoch 739/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7890\n",
      "Epoch 740/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7837\n",
      "Epoch 741/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7880\n",
      "Epoch 742/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.7847\n",
      "Epoch 743/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7799\n",
      "Epoch 744/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7825\n",
      "Epoch 745/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7866\n",
      "Epoch 746/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7836\n",
      "Epoch 747/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7858\n",
      "Epoch 748/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7863\n",
      "Epoch 749/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7896\n",
      "Epoch 750/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.7882\n",
      "Epoch 751/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7856\n",
      "Epoch 752/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7849\n",
      "Epoch 753/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7875\n",
      "Epoch 754/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7898\n",
      "Epoch 755/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7809\n",
      "Epoch 756/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7829\n",
      "Epoch 757/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7861\n",
      "Epoch 758/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4414 - accuracy: 0.7824\n",
      "Epoch 759/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7832\n",
      "Epoch 760/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.7878\n",
      "Epoch 761/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7906\n",
      "Epoch 762/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.7852\n",
      "Epoch 763/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7852\n",
      "Epoch 764/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7841\n",
      "Epoch 765/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7832\n",
      "Epoch 766/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7873\n",
      "Epoch 767/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.7891\n",
      "Epoch 768/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7874\n",
      "Epoch 769/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.7840\n",
      "Epoch 770/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7841\n",
      "Epoch 771/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7888\n",
      "Epoch 772/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7870\n",
      "Epoch 773/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7856\n",
      "Epoch 774/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7801\n",
      "Epoch 775/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.7820\n",
      "Epoch 776/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7845\n",
      "Epoch 777/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7873\n",
      "Epoch 778/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7851\n",
      "Epoch 779/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7899\n",
      "Epoch 780/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7921\n",
      "Epoch 781/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4317 - accuracy: 0.7824\n",
      "Epoch 782/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7928\n",
      "Epoch 783/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7886\n",
      "Epoch 784/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4351 - accuracy: 0.7856\n",
      "Epoch 785/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.7856\n",
      "Epoch 786/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7841\n",
      "Epoch 787/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7883\n",
      "Epoch 788/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7886\n",
      "Epoch 789/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7859\n",
      "Epoch 790/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7891\n",
      "Epoch 791/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4374 - accuracy: 0.7817\n",
      "Epoch 792/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7896\n",
      "Epoch 793/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7830\n",
      "Epoch 794/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7830\n",
      "Epoch 795/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7914\n",
      "Epoch 796/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7874\n",
      "Epoch 797/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7908\n",
      "Epoch 798/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7870\n",
      "Epoch 799/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7852\n",
      "Epoch 800/800\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c79128d670>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.fit(X1, Y1, epochs=800, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f9009de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y1_pred1 = nn_model.predict(X1_t)\n",
    "predictions11 = [round(value[0]) for value in y1_pred1]\n",
    "pred1_df1 = pd.DataFrame(data=predictions11, columns=['Transported'])\n",
    "pred1_df1['Transported'] = pred1_df1['Transported'].astype(bool)\n",
    "df1_test1 = pd.concat([df_id, pred1_df1], axis=1)\n",
    "df1_test1.to_csv('..\\\\nn1 with dropout rev5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b65d0b80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "272/272 [==============================] - 1s 1ms/step - loss: 0.5899 - accuracy: 0.6766\n",
      "Epoch 2/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5459 - accuracy: 0.7263\n",
      "Epoch 3/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5207 - accuracy: 0.7384\n",
      "Epoch 4/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7524\n",
      "Epoch 5/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7648\n",
      "Epoch 6/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7694\n",
      "Epoch 7/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7732\n",
      "Epoch 8/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7779\n",
      "Epoch 9/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.7833\n",
      "Epoch 10/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7826\n",
      "Epoch 11/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7852\n",
      "Epoch 12/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7913\n",
      "Epoch 13/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7905\n",
      "Epoch 14/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7914\n",
      "Epoch 15/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7928\n",
      "Epoch 16/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.7868\n",
      "Epoch 17/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.7908\n",
      "Epoch 18/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4332 - accuracy: 0.7926\n",
      "Epoch 19/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4324 - accuracy: 0.7935\n",
      "Epoch 20/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7967\n",
      "Epoch 21/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.7926\n",
      "Epoch 22/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.7965\n",
      "Epoch 23/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7991\n",
      "Epoch 24/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.7982\n",
      "Epoch 25/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.7960\n",
      "Epoch 26/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4217 - accuracy: 0.7982\n",
      "Epoch 27/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.7950\n",
      "Epoch 28/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4220 - accuracy: 0.7949\n",
      "Epoch 29/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.7990\n",
      "Epoch 30/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4207 - accuracy: 0.7986\n",
      "Epoch 31/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4177 - accuracy: 0.7995\n",
      "Epoch 32/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.7956\n",
      "Epoch 33/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4124 - accuracy: 0.8027\n",
      "Epoch 34/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4175 - accuracy: 0.8003\n",
      "Epoch 35/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4178 - accuracy: 0.7978\n",
      "Epoch 36/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.8031\n",
      "Epoch 37/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.7991\n",
      "Epoch 38/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8000\n",
      "Epoch 39/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4166 - accuracy: 0.7965\n",
      "Epoch 40/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.8018\n",
      "Epoch 41/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8031\n",
      "Epoch 42/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.7957\n",
      "Epoch 43/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.7987\n",
      "Epoch 44/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4077 - accuracy: 0.8023\n",
      "Epoch 45/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8062\n",
      "Epoch 46/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4109 - accuracy: 0.7968\n",
      "Epoch 47/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8009\n",
      "Epoch 48/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.7983\n",
      "Epoch 49/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8005\n",
      "Epoch 50/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8052\n",
      "Epoch 51/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8046\n",
      "Epoch 52/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8023\n",
      "Epoch 53/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4081 - accuracy: 0.8064\n",
      "Epoch 54/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8073\n",
      "Epoch 55/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4039 - accuracy: 0.8038\n",
      "Epoch 56/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8012\n",
      "Epoch 57/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4033 - accuracy: 0.8058\n",
      "Epoch 58/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8061\n",
      "Epoch 59/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8056\n",
      "Epoch 60/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8038\n",
      "Epoch 61/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4094 - accuracy: 0.8017\n",
      "Epoch 62/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8024\n",
      "Epoch 63/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8025\n",
      "Epoch 64/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8010\n",
      "Epoch 65/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4002 - accuracy: 0.8039\n",
      "Epoch 66/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8090\n",
      "Epoch 67/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8073\n",
      "Epoch 68/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4029 - accuracy: 0.8058\n",
      "Epoch 69/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8038\n",
      "Epoch 70/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8055\n",
      "Epoch 71/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4046 - accuracy: 0.8039\n",
      "Epoch 72/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8056\n",
      "Epoch 73/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8063\n",
      "Epoch 74/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8069\n",
      "Epoch 75/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8058\n",
      "Epoch 76/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8087\n",
      "Epoch 77/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8067\n",
      "Epoch 78/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8059\n",
      "Epoch 79/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8087\n",
      "Epoch 80/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.7997\n",
      "Epoch 81/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3962 - accuracy: 0.8088\n",
      "Epoch 82/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8090\n",
      "Epoch 83/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8090\n",
      "Epoch 84/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3962 - accuracy: 0.8101\n",
      "Epoch 85/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8075\n",
      "Epoch 86/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8116\n",
      "Epoch 87/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3930 - accuracy: 0.8056\n",
      "Epoch 88/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3898 - accuracy: 0.8132\n",
      "Epoch 89/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8050\n",
      "Epoch 90/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3964 - accuracy: 0.8040\n",
      "Epoch 91/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3981 - accuracy: 0.8054\n",
      "Epoch 92/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8066\n",
      "Epoch 93/400\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8067\n",
      "Epoch 94/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8050\n",
      "Epoch 95/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8025\n",
      "Epoch 96/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8026\n",
      "Epoch 97/400\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.3974 - accuracy: 0.8084\n",
      "Epoch 98/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8057\n",
      "Epoch 99/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8029\n",
      "Epoch 100/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8043\n",
      "Epoch 101/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8077\n",
      "Epoch 102/400\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.3991 - accuracy: 0.8089\n",
      "Epoch 103/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3934 - accuracy: 0.8044\n",
      "Epoch 104/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8092\n",
      "Epoch 105/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8090\n",
      "Epoch 106/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8059\n",
      "Epoch 107/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8059\n",
      "Epoch 108/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8038\n",
      "Epoch 109/400\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.3971 - accuracy: 0.8093\n",
      "Epoch 110/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8080\n",
      "Epoch 111/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8063\n",
      "Epoch 112/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8084\n",
      "Epoch 113/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8105\n",
      "Epoch 114/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8075\n",
      "Epoch 115/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.8057\n",
      "Epoch 116/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8072\n",
      "Epoch 117/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8073\n",
      "Epoch 118/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8052\n",
      "Epoch 119/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8064\n",
      "Epoch 120/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.8048\n",
      "Epoch 121/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8087\n",
      "Epoch 122/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8042\n",
      "Epoch 123/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8046\n",
      "Epoch 124/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8097\n",
      "Epoch 125/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8038\n",
      "Epoch 126/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8077\n",
      "Epoch 127/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8074\n",
      "Epoch 128/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8044\n",
      "Epoch 129/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8048\n",
      "Epoch 130/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8061\n",
      "Epoch 131/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3918 - accuracy: 0.8082\n",
      "Epoch 132/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8086\n",
      "Epoch 133/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8070\n",
      "Epoch 134/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8095\n",
      "Epoch 135/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8009\n",
      "Epoch 136/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8052\n",
      "Epoch 137/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8064\n",
      "Epoch 138/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8075\n",
      "Epoch 139/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8069\n",
      "Epoch 140/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8072\n",
      "Epoch 141/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8082\n",
      "Epoch 142/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8100\n",
      "Epoch 143/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8044\n",
      "Epoch 144/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8098\n",
      "Epoch 145/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8135\n",
      "Epoch 146/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8086\n",
      "Epoch 147/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8069\n",
      "Epoch 148/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8070\n",
      "Epoch 149/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8139\n",
      "Epoch 150/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8101\n",
      "Epoch 151/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8115\n",
      "Epoch 152/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8090\n",
      "Epoch 153/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8058\n",
      "Epoch 154/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.4007 - accuracy: 0.8058\n",
      "Epoch 155/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8101\n",
      "Epoch 156/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8092\n",
      "Epoch 157/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8096\n",
      "Epoch 158/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8016\n",
      "Epoch 159/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3941 - accuracy: 0.8085\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8086\n",
      "Epoch 161/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8057\n",
      "Epoch 162/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8103\n",
      "Epoch 163/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8014\n",
      "Epoch 164/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8104\n",
      "Epoch 165/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8077\n",
      "Epoch 166/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8054\n",
      "Epoch 167/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8092\n",
      "Epoch 168/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8118\n",
      "Epoch 169/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8072\n",
      "Epoch 170/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8104\n",
      "Epoch 171/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8086\n",
      "Epoch 172/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8090\n",
      "Epoch 173/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3951 - accuracy: 0.8102\n",
      "Epoch 174/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8059\n",
      "Epoch 175/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8089\n",
      "Epoch 176/400\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.3922 - accuracy: 0.8131\n",
      "Epoch 177/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8075\n",
      "Epoch 178/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8128\n",
      "Epoch 179/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8140\n",
      "Epoch 180/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8074\n",
      "Epoch 181/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8147\n",
      "Epoch 182/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8067\n",
      "Epoch 183/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8120\n",
      "Epoch 184/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8042\n",
      "Epoch 185/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8096\n",
      "Epoch 186/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8132\n",
      "Epoch 187/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8134\n",
      "Epoch 188/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8093\n",
      "Epoch 189/400\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.3909 - accuracy: 0.8100\n",
      "Epoch 190/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8069\n",
      "Epoch 191/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8096\n",
      "Epoch 192/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8143\n",
      "Epoch 193/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8092\n",
      "Epoch 194/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8102\n",
      "Epoch 195/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8130\n",
      "Epoch 196/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8074\n",
      "Epoch 197/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8115\n",
      "Epoch 198/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8105\n",
      "Epoch 199/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8050\n",
      "Epoch 200/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8126\n",
      "Epoch 201/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8088\n",
      "Epoch 202/400\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.3906 - accuracy: 0.8110\n",
      "Epoch 203/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8090\n",
      "Epoch 204/400\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.8116\n",
      "Epoch 205/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8041\n",
      "Epoch 206/400\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.3926 - accuracy: 0.8081\n",
      "Epoch 207/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8141\n",
      "Epoch 208/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8048\n",
      "Epoch 209/400\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.3943 - accuracy: 0.8092\n",
      "Epoch 210/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8118\n",
      "Epoch 211/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8118\n",
      "Epoch 212/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8139\n",
      "Epoch 213/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8100\n",
      "Epoch 214/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8100\n",
      "Epoch 215/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8112\n",
      "Epoch 216/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3911 - accuracy: 0.8077\n",
      "Epoch 217/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8138\n",
      "Epoch 218/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8089\n",
      "Epoch 219/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8066\n",
      "Epoch 220/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8102\n",
      "Epoch 221/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8079\n",
      "Epoch 222/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8146\n",
      "Epoch 223/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8055\n",
      "Epoch 224/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8110\n",
      "Epoch 225/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8115\n",
      "Epoch 226/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8097\n",
      "Epoch 227/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8134\n",
      "Epoch 228/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8110\n",
      "Epoch 229/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8071\n",
      "Epoch 230/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8086\n",
      "Epoch 231/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8130\n",
      "Epoch 232/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8144\n",
      "Epoch 233/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8038\n",
      "Epoch 234/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8081\n",
      "Epoch 235/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8055\n",
      "Epoch 236/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8105\n",
      "Epoch 237/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8070\n",
      "Epoch 238/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8084\n",
      "Epoch 239/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8113\n",
      "Epoch 240/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8127\n",
      "Epoch 241/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8120\n",
      "Epoch 242/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8110\n",
      "Epoch 243/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8110\n",
      "Epoch 244/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8095\n",
      "Epoch 245/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8056\n",
      "Epoch 246/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8066\n",
      "Epoch 247/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8092\n",
      "Epoch 248/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8078\n",
      "Epoch 249/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8080\n",
      "Epoch 250/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8049\n",
      "Epoch 251/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8174\n",
      "Epoch 252/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8097\n",
      "Epoch 253/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8072\n",
      "Epoch 254/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8093\n",
      "Epoch 255/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8089\n",
      "Epoch 256/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8131\n",
      "Epoch 257/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8131\n",
      "Epoch 258/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8096\n",
      "Epoch 259/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8056\n",
      "Epoch 260/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8092\n",
      "Epoch 261/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8075\n",
      "Epoch 262/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8153\n",
      "Epoch 263/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8049\n",
      "Epoch 264/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8096\n",
      "Epoch 265/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8064\n",
      "Epoch 266/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8117\n",
      "Epoch 267/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8107\n",
      "Epoch 268/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8124\n",
      "Epoch 269/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8089\n",
      "Epoch 270/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8090\n",
      "Epoch 271/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8149\n",
      "Epoch 272/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8108\n",
      "Epoch 273/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8070\n",
      "Epoch 274/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8142\n",
      "Epoch 275/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8119\n",
      "Epoch 276/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8088\n",
      "Epoch 277/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8139\n",
      "Epoch 278/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8138\n",
      "Epoch 279/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8067\n",
      "Epoch 280/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8084\n",
      "Epoch 281/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3867 - accuracy: 0.8090\n",
      "Epoch 282/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3924 - accuracy: 0.8080\n",
      "Epoch 283/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8117\n",
      "Epoch 284/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8096\n",
      "Epoch 285/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8088\n",
      "Epoch 286/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8120\n",
      "Epoch 287/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8098\n",
      "Epoch 288/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8079\n",
      "Epoch 289/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3909 - accuracy: 0.8079\n",
      "Epoch 290/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8121\n",
      "Epoch 291/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8110\n",
      "Epoch 292/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8110\n",
      "Epoch 293/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8172\n",
      "Epoch 294/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3913 - accuracy: 0.8110\n",
      "Epoch 295/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8066\n",
      "Epoch 296/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8164\n",
      "Epoch 297/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8161\n",
      "Epoch 298/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8085\n",
      "Epoch 299/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8072\n",
      "Epoch 300/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8074\n",
      "Epoch 301/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8119\n",
      "Epoch 302/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8105\n",
      "Epoch 303/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8134\n",
      "Epoch 304/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8153\n",
      "Epoch 305/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8111\n",
      "Epoch 306/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8109\n",
      "Epoch 307/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8100\n",
      "Epoch 308/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8127\n",
      "Epoch 309/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8054\n",
      "Epoch 310/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8098\n",
      "Epoch 311/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8124\n",
      "Epoch 312/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8093\n",
      "Epoch 313/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8140\n",
      "Epoch 314/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8100\n",
      "Epoch 315/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8118\n",
      "Epoch 316/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8100\n",
      "Epoch 317/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8073\n",
      "Epoch 318/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.8063\n",
      "Epoch 319/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8058\n",
      "Epoch 320/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8131\n",
      "Epoch 321/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8062\n",
      "Epoch 322/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8116\n",
      "Epoch 323/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8130\n",
      "Epoch 324/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8110\n",
      "Epoch 325/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8113\n",
      "Epoch 326/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8027\n",
      "Epoch 327/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8159\n",
      "Epoch 328/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8162\n",
      "Epoch 329/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8101\n",
      "Epoch 330/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8131\n",
      "Epoch 331/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8120\n",
      "Epoch 332/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8102\n",
      "Epoch 333/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8149\n",
      "Epoch 334/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8159\n",
      "Epoch 335/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8121\n",
      "Epoch 336/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8113\n",
      "Epoch 337/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8082\n",
      "Epoch 338/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8108\n",
      "Epoch 339/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3880 - accuracy: 0.8096\n",
      "Epoch 340/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8089\n",
      "Epoch 341/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8096\n",
      "Epoch 342/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8078\n",
      "Epoch 343/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8095\n",
      "Epoch 344/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8115\n",
      "Epoch 345/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8107\n",
      "Epoch 346/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8136\n",
      "Epoch 347/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8078\n",
      "Epoch 348/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8120\n",
      "Epoch 349/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8073\n",
      "Epoch 350/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8118\n",
      "Epoch 351/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8097\n",
      "Epoch 352/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8150\n",
      "Epoch 353/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8112\n",
      "Epoch 354/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8094\n",
      "Epoch 355/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8139\n",
      "Epoch 356/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8101\n",
      "Epoch 357/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8156\n",
      "Epoch 358/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8128\n",
      "Epoch 359/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8105\n",
      "Epoch 360/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8119\n",
      "Epoch 361/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8090\n",
      "Epoch 362/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8088\n",
      "Epoch 363/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8108\n",
      "Epoch 364/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8071\n",
      "Epoch 365/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8084\n",
      "Epoch 366/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8081\n",
      "Epoch 367/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8085\n",
      "Epoch 368/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8103\n",
      "Epoch 369/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8112\n",
      "Epoch 370/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8138\n",
      "Epoch 371/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8050\n",
      "Epoch 372/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8120\n",
      "Epoch 373/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8066\n",
      "Epoch 374/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8081\n",
      "Epoch 375/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8115\n",
      "Epoch 376/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8103\n",
      "Epoch 377/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8116\n",
      "Epoch 378/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8107\n",
      "Epoch 379/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8078\n",
      "Epoch 380/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8126\n",
      "Epoch 381/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8084\n",
      "Epoch 382/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8107\n",
      "Epoch 383/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8169\n",
      "Epoch 384/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8119\n",
      "Epoch 385/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3863 - accuracy: 0.8082\n",
      "Epoch 386/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8115\n",
      "Epoch 387/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8107\n",
      "Epoch 388/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8134\n",
      "Epoch 389/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8055\n",
      "Epoch 390/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8092\n",
      "Epoch 391/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8126\n",
      "Epoch 392/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8123\n",
      "Epoch 393/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8119\n",
      "Epoch 394/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8128\n",
      "Epoch 395/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8125\n",
      "Epoch 396/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3875 - accuracy: 0.8105\n",
      "Epoch 397/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8115\n",
      "Epoch 398/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8127\n",
      "Epoch 399/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8113\n",
      "Epoch 400/400\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c78c3126d0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model3.fit(X1, Y1, epochs=400, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c77c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 744us/step\n"
     ]
    }
   ],
   "source": [
    "y1_pred1 = nn_model3.predict(X1_t)\n",
    "predictions11 = [round(value[0]) for value in y1_pred1]\n",
    "pred1_df1 = pd.DataFrame(data=predictions11, columns=['Transported'])\n",
    "pred1_df1['Transported'] = pred1_df1['Transported'].astype(bool)\n",
    "df1_test1 = pd.concat([df_id, pred1_df1], axis=1)\n",
    "df1_test1.to_csv('..\\\\nn1 with dropout rev3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35704b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a29e99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_model1.fit(X1, Y1, epochs=400, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ecbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_model2.fit(X2, Y2, epochs=400, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4fba913",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_t, df_id = get_test_data_transform_rev1()\n",
    "X2_t, df_id = get_test_data_transform_rev2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred1 = nn_model1.predict(X1_t)\n",
    "y1_pred2 = nn_model1.predict(X2_t)\n",
    "y2_pred1 = nn_model2.predict(X1_t)\n",
    "y2_pred2 = nn_model2.predict(X2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions11 = [round(value[0]) for value in y1_pred1]\n",
    "predictions12 = [round(value[0]) for value in y1_pred2]\n",
    "predictions21 = [round(value[0]) for value in y2_pred1]\n",
    "predictions22 = [round(value[0]) for value in y2_pred2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905481f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_df1 = pd.DataFrame(data=predictions11, columns=['Transported'])\n",
    "pred1_df2 = pd.DataFrame(data=predictions12, columns=['Transported'])\n",
    "pred2_df1 = pd.DataFrame(data=predictions21, columns=['Transported'])\n",
    "pred2_df2 = pd.DataFrame(data=predictions22, columns=['Transported'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_df1['Transported'] = pred1_df1['Transported'].astype(bool)\n",
    "pred1_df2['Transported'] = pred1_df2['Transported'].astype(bool)\n",
    "pred2_df1['Transported'] = pred2_df1['Transported'].astype(bool)\n",
    "pred2_df2['Transported'] = pred2_df2['Transported'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e33b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_test1 = pd.concat([df_id, pred1_df1], axis=1)\n",
    "df1_test2 = pd.concat([df_id, pred1_df2], axis=1)\n",
    "df2_test1 = pd.concat([df_id, pred2_df1], axis=1)\n",
    "df2_test2 = pd.concat([df_id, pred2_df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_test1.to_csv('submit nn11.csv', index=False)\n",
    "df1_test2.to_csv('submit nn12.csv', index=False)\n",
    "df2_test1.to_csv('submit nn21.csv', index=False)\n",
    "df2_test2.to_csv('submit nn22.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = iso.fit_predict(X2)\n",
    "mask = yhat != -1\n",
    "outies = yhat == -1\n",
    "# X_train, y_train = X_train_.loc[mask, :], y_train_.loc[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15548917",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X2.values, Y2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896150b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_outies, Y_outies = X2.loc[outies, :], Y2.loc[outies, :]\n",
    "X_inies, Y_inies = X2.loc[mask, :], Y2.loc[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507acda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_outies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca2b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_inies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3866af29",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_ins = XGBClassifier(n_estimators=70)  # , num_parallel_tree=10)  #, n_jobs=100)\n",
    "xgb_model_ins.fit(X_inies, Y_inies)\n",
    "xgb_model_outs = XGBClassifier(n_estimators=70)  # , num_parallel_tree=10)  #, n_jobs=100)\n",
    "xgb_model_outs.fit(X_outies, Y_outies)\n",
    "# y_pred = xgb_model_ins.predict(X_test)\n",
    "# predictions = [round(value) for value in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv(files[1])  # the test data\n",
    "dfct = transform_data_rev2(dft)\n",
    "dfdt = dfct.loc[:, dfct.columns != 'PassengerId']  # passanger id should not be input for training\n",
    "X2t = dfdt\n",
    "print(len(X2t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6bbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_t = iso.predict(X2t)\n",
    "mask_t = yhat_t != -1\n",
    "outies_t = yhat_t == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940203d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_ins = X2t.loc[mask_t, :]\n",
    "x_test_outs = X2t.loc[outies_t, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ins = xgb_model_ins.predict(x_test_ins)\n",
    "y_pred_outs = xgb_model_outs.predict(x_test_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75394c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcta = dfct[['PassengerId']]\n",
    "pass_id_ins = dfcta.loc[mask_t, :]\n",
    "pass_id_outs = dfcta.loc[outies_t, :]\n",
    "\n",
    "pred_df_ins = pd.DataFrame(data=pass_id_ins, columns=['Transported'])\n",
    "pred_df_ins['Transported'] = pred_df_ins['Transported'].astype(bool)\n",
    "df_test_ins = pd.concat([pass_id_ins, pred_df_ins], axis=1)\n",
    "\n",
    "pred_df_outs = pd.DataFrame(data=pass_id_outs, columns=['Transported'])\n",
    "pred_df_outs['Transported'] = pred_df_outs['Transported'].astype(bool)\n",
    "df_test_outs = pd.concat([pass_id_outs, pred_df_outs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ins.to_csv('..\\\\revA\\\\xgboost_ins.csv', index=False)\n",
    "df_test_outs.to_csv('..\\\\revA\\\\xgboost_outs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a2554a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "895869f1",
   "metadata": {},
   "source": [
    "# Testing iso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b617cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso2 = IsolationForest(contamination=0.1)\n",
    "yhat = iso2.fit_predict(dfc2)\n",
    "mask = yhat != -1\n",
    "outies = yhat == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_train = dfc2[outies]\n",
    "outliers_train['Transported'] = outliers_train['Transported'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deea0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_train.to_csv('..\\\\outliers_iso_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bee531d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb570686",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtale.show(outliers_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cc5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddff = dfc2\n",
    "ddff['Transported'] = ddff['Transported'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8e7ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtale.show(ddff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b093d",
   "metadata": {},
   "source": [
    "# Lazy Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46835eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "948c0473",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1, df_id = get_train_data_transform_rev1()\n",
    "X2, Y2, df_id = get_train_data_transform_rev2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fee18b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 29/29 [00:10<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, test_size=.5,random_state =123)\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9764702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "LGBMClassifier                     0.81               0.81     0.81      0.81   \n",
       "RandomForestClassifier             0.81               0.81     0.81      0.81   \n",
       "XGBClassifier                      0.80               0.80     0.80      0.80   \n",
       "LogisticRegression                 0.80               0.80     0.80      0.80   \n",
       "SVC                                0.80               0.80     0.80      0.80   \n",
       "AdaBoostClassifier                 0.80               0.80     0.80      0.80   \n",
       "ExtraTreesClassifier               0.80               0.80     0.80      0.80   \n",
       "NuSVC                              0.80               0.80     0.80      0.80   \n",
       "CalibratedClassifierCV             0.80               0.80     0.80      0.80   \n",
       "LinearSVC                          0.80               0.80     0.80      0.80   \n",
       "BaggingClassifier                  0.79               0.79     0.79      0.79   \n",
       "RidgeClassifierCV                  0.78               0.78     0.78      0.78   \n",
       "RidgeClassifier                    0.78               0.78     0.78      0.78   \n",
       "LinearDiscriminantAnalysis         0.78               0.78     0.78      0.78   \n",
       "KNeighborsClassifier               0.77               0.77     0.77      0.77   \n",
       "SGDClassifier                      0.77               0.77     0.77      0.77   \n",
       "Perceptron                         0.77               0.77     0.77      0.77   \n",
       "NearestCentroid                    0.76               0.76     0.76      0.76   \n",
       "BernoulliNB                        0.75               0.75     0.75      0.75   \n",
       "DecisionTreeClassifier             0.74               0.74     0.74      0.74   \n",
       "LabelSpreading                     0.74               0.74     0.74      0.74   \n",
       "LabelPropagation                   0.74               0.74     0.74      0.74   \n",
       "ExtraTreeClassifier                0.74               0.74     0.74      0.74   \n",
       "PassiveAggressiveClassifier        0.74               0.73     0.73      0.73   \n",
       "GaussianNB                         0.62               0.61     0.61      0.56   \n",
       "QuadraticDiscriminantAnalysis      0.57               0.57     0.57      0.48   \n",
       "DummyClassifier                    0.51               0.50     0.50      0.34   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "LGBMClassifier                       0.12  \n",
       "RandomForestClassifier               0.41  \n",
       "XGBClassifier                        0.81  \n",
       "LogisticRegression                   0.03  \n",
       "SVC                                  1.22  \n",
       "AdaBoostClassifier                   0.20  \n",
       "ExtraTreesClassifier                 0.40  \n",
       "NuSVC                                1.33  \n",
       "CalibratedClassifierCV               0.69  \n",
       "LinearSVC                            0.22  \n",
       "BaggingClassifier                    0.14  \n",
       "RidgeClassifierCV                    0.02  \n",
       "RidgeClassifier                      0.02  \n",
       "LinearDiscriminantAnalysis           0.06  \n",
       "KNeighborsClassifier                 0.52  \n",
       "SGDClassifier                        0.03  \n",
       "Perceptron                           0.02  \n",
       "NearestCentroid                      0.01  \n",
       "BernoulliNB                          0.02  \n",
       "DecisionTreeClassifier               0.03  \n",
       "LabelSpreading                       2.29  \n",
       "LabelPropagation                     1.43  \n",
       "ExtraTreeClassifier                  0.02  \n",
       "PassiveAggressiveClassifier          0.02  \n",
       "GaussianNB                           0.02  \n",
       "QuadraticDiscriminantAnalysis        0.02  \n",
       "DummyClassifier                      0.01  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c14e8c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 29/29 [00:09<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, Y2, test_size=.5,random_state =123)\n",
    "clf2 = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models2, predictions2 = clf2.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77fcbb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVC</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalibratedClassifierCV</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearDiscriminantAnalysis</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NearestCentroid</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BernoulliNB</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelSpreading</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>2.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LabelPropagation</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNB</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QuadraticDiscriminantAnalysis</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyClassifier</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
       "Model                                                                           \n",
       "LGBMClassifier                     0.81               0.81     0.81      0.81   \n",
       "RandomForestClassifier             0.81               0.81     0.81      0.81   \n",
       "AdaBoostClassifier                 0.80               0.80     0.80      0.80   \n",
       "ExtraTreesClassifier               0.80               0.80     0.80      0.80   \n",
       "LogisticRegression                 0.80               0.80     0.80      0.80   \n",
       "NuSVC                              0.80               0.80     0.80      0.80   \n",
       "XGBClassifier                      0.80               0.80     0.80      0.80   \n",
       "SVC                                0.80               0.80     0.80      0.80   \n",
       "CalibratedClassifierCV             0.80               0.80     0.80      0.80   \n",
       "LinearSVC                          0.80               0.80     0.80      0.80   \n",
       "BaggingClassifier                  0.79               0.79     0.79      0.79   \n",
       "RidgeClassifierCV                  0.78               0.78     0.78      0.78   \n",
       "RidgeClassifier                    0.78               0.78     0.78      0.78   \n",
       "LinearDiscriminantAnalysis         0.78               0.78     0.78      0.78   \n",
       "KNeighborsClassifier               0.77               0.77     0.77      0.77   \n",
       "SGDClassifier                      0.76               0.76     0.76      0.76   \n",
       "NearestCentroid                    0.76               0.76     0.76      0.76   \n",
       "BernoulliNB                        0.75               0.75     0.75      0.75   \n",
       "DecisionTreeClassifier             0.75               0.75     0.75      0.75   \n",
       "PassiveAggressiveClassifier        0.74               0.74     0.74      0.74   \n",
       "LabelSpreading                     0.74               0.74     0.74      0.74   \n",
       "LabelPropagation                   0.74               0.74     0.74      0.74   \n",
       "ExtraTreeClassifier                0.73               0.73     0.73      0.73   \n",
       "Perceptron                         0.69               0.69     0.69      0.69   \n",
       "GaussianNB                         0.62               0.61     0.61      0.56   \n",
       "QuadraticDiscriminantAnalysis      0.57               0.57     0.57      0.48   \n",
       "DummyClassifier                    0.51               0.50     0.50      0.34   \n",
       "\n",
       "                               Time Taken  \n",
       "Model                                      \n",
       "LGBMClassifier                       0.10  \n",
       "RandomForestClassifier               0.41  \n",
       "AdaBoostClassifier                   0.23  \n",
       "ExtraTreesClassifier                 0.39  \n",
       "LogisticRegression                   0.03  \n",
       "NuSVC                                1.36  \n",
       "XGBClassifier                        0.19  \n",
       "SVC                                  1.22  \n",
       "CalibratedClassifierCV               0.72  \n",
       "LinearSVC                            0.22  \n",
       "BaggingClassifier                    0.12  \n",
       "RidgeClassifierCV                    0.02  \n",
       "RidgeClassifier                      0.02  \n",
       "LinearDiscriminantAnalysis           0.03  \n",
       "KNeighborsClassifier                 0.49  \n",
       "SGDClassifier                        0.03  \n",
       "NearestCentroid                      0.01  \n",
       "BernoulliNB                          0.02  \n",
       "DecisionTreeClassifier               0.03  \n",
       "PassiveAggressiveClassifier          0.02  \n",
       "LabelSpreading                       2.23  \n",
       "LabelPropagation                     1.38  \n",
       "ExtraTreeClassifier                  0.02  \n",
       "Perceptron                           0.01  \n",
       "GaussianNB                           0.02  \n",
       "QuadraticDiscriminantAnalysis        0.02  \n",
       "DummyClassifier                      0.01  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11577b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_t, df_id = get_test_data_transform_rev1()\n",
    "X2_t, df_id = get_test_data_transform_rev2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44b32bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f646b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtbm_model1 = LGBMClassifier()\n",
    "lgtbm_model2 = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2858db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtbm_model1.fit(X1, Y1)\n",
    "lgtbm_model2.fit(X2, Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtbm1_pred1 = lgtbm_model1.predict(X1_t)\n",
    "lgtbm1_pred2 = lgtbm_model1.predict(X2_t)\n",
    "lgtbm2_pred1 = lgtbm_model2.predict(X1_t)\n",
    "lgtbm2_pred2 = lgtbm_model2.predict(X2_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad0bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_df1 = pd.DataFrame(data=lgtbm1_pred1, columns=['Transported'])\n",
    "pred1_df1['Transported'] = pred1_df1['Transported'].astype(bool)\n",
    "df1_test1 = pd.concat([df_id, pred1_df1], axis=1)\n",
    "df1_test1.to_csv('lgtbm11.csv', index=False)\n",
    "\n",
    "pred1_df2 = pd.DataFrame(data=lgtbm1_pred2, columns=['Transported'])\n",
    "pred1_df2['Transported'] = pred1_df2['Transported'].astype(bool)\n",
    "df1_test2 = pd.concat([df_id, pred1_df2], axis=1)\n",
    "df1_test2.to_csv('lgtbm12.csv', index=False)\n",
    "\n",
    "\n",
    "pred2_df1 = pd.DataFrame(data=lgtbm2_pred1, columns=['Transported'])\n",
    "pred2_df1['Transported'] = pred2_df1['Transported'].astype(bool)\n",
    "df2_test1 = pd.concat([df_id, pred2_df1], axis=1)\n",
    "df2_test1.to_csv('lgtbm21.csv', index=False)\n",
    "\n",
    "pred2_df2 = pd.DataFrame(data=lgtbm2_pred2, columns=['Transported'])\n",
    "pred2_df2['Transported'] = pred2_df2['Transported'].astype(bool)\n",
    "df2_test2 = pd.concat([df_id, pred2_df2], axis=1)\n",
    "df2_test2.to_csv('lgtbm22.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42d44388",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model_t = LGBMClassifier(reg_lambda=0.013, reg_alpha=0.0, n_estimators=220, learning_rate=0.13, \n",
    "                              importance_type='split', class_weight=None, boosting_type='dart')\n",
    "lgbm_model_t.fit(X1, Y1)\n",
    "lgbm_pred = lgbm_model_t.predict(X2_t)\n",
    "pred_df = pd.DataFrame(data=lgbm_pred, columns=['Transported'])\n",
    "pred_df['Transported'] = pred_df['Transported'].astype(bool)\n",
    "df_test = pd.concat([df_id, pred_df], axis=1)\n",
    "df_test.to_csv('..\\\\Spaceship Titanic\\\\LGBM1_tuned2_rev1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a616a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_t = RandomForestClassifier(oob_score=True, n_estimators=215, min_samples_split=3, max_samples=0.9, \n",
    "                                    max_features='sqrt', criterion='entropy', class_weight='balanced_subsample')\n",
    "\n",
    "rf_model_t.fit(X1, Y1)\n",
    "rf_pred = rf_model_t.predict(X1_t)\n",
    "pred_df = pd.DataFrame(data=rf_pred, columns=['Transported'])\n",
    "pred_df['Transported'] = pred_df['Transported'].astype(bool)\n",
    "df_test = pd.concat([df_id, pred_df], axis=1)\n",
    "df_test.to_csv('..\\\\Spaceship Titanic\\\\RF_tuned_rev1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b53aa9",
   "metadata": {},
   "source": [
    "# SEARCH: Hyper Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "470ec18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform, rv_discrete\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55285fff",
   "metadata": {},
   "source": [
    "### Model to search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "526e11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d25e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09bf7dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ee03320",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space['n_estimators'] = np.arange(50,250,25)  # np.arange(50,600,25)\n",
    "space['criterion'] = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "space['min_samples_split'] = [2, 4, 6]\n",
    "space['max_features'] = ['sqrt', 'log2', None]\n",
    "space['n_jobs'] = [4]\n",
    "space['class_weight'] = ['balanced', 'balanced_subsample']\n",
    "space['oob_score'] = [True, False]\n",
    "space['max_samples'] = np.arange(0.1,1.0,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3833273c",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e263bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1, df_id = get_train_data_transform_rev1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a02b384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8055145078017186\n",
      "Best Hyperparameters: {'oob_score': True, 'n_jobs': 4, 'n_estimators': 225, 'min_samples_split': 4, 'max_samples': 0.7000000000000001, 'max_features': 'sqrt', 'criterion': 'entropy', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1e0e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space['n_estimators'] = [225]\n",
    "space['criterion'] = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "space['min_samples_split'] = [2, 4, 6]\n",
    "space['max_features'] = ['sqrt', 'log2', None]\n",
    "space['n_jobs'] = [4]\n",
    "space['class_weight'] = ['balanced', 'balanced_subsample']\n",
    "space['oob_score'] = [True]\n",
    "space['max_samples'] = np.arange(0.1,1.0,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d27056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8063579487586471\n",
      "Best Hyperparameters: {'oob_score': True, 'n_jobs': 4, 'n_estimators': 225, 'min_samples_split': 4, 'max_samples': 0.9, 'max_features': 'log2', 'criterion': 'entropy', 'class_weight': 'balanced_subsample'}\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9b24509",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space['n_estimators'] = [215, 225, 240]\n",
    "space['criterion'] = [\"entropy\"]\n",
    "space['min_samples_split'] = [3, 4, 5]\n",
    "space['max_features'] = ['sqrt', 'log2', None]\n",
    "space['n_jobs'] = [4]\n",
    "space['class_weight'] = ['balanced', 'balanced_subsample']\n",
    "space['oob_score'] = [True]\n",
    "space['max_samples'] = [0.9, 0.999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2afe80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8067025558950482\n",
      "Best Hyperparameters: {'oob_score': True, 'n_jobs': 8, 'n_estimators': 215, 'min_samples_split': 3, 'max_samples': 0.9, 'max_features': 'sqrt', 'criterion': 'entropy', 'class_weight': 'balanced_subsample'}\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53e39623",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space['n_estimators'] = [190, 205, 215, 220]\n",
    "space['criterion'] = [\"entropy\"]\n",
    "space['min_samples_split'] = [2, 3, 4]\n",
    "space['max_features'] = ['sqrt', 'log2', None]\n",
    "space['n_jobs'] = [4]\n",
    "space['class_weight'] = ['balanced', 'balanced_subsample']\n",
    "space['oob_score'] = [True]\n",
    "space['max_samples'] = [0.8, 0.9, 0.999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0d5f519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8065492110101449\n",
      "Best Hyperparameters: {'oob_score': True, 'n_jobs': 4, 'n_estimators': 220, 'min_samples_split': 3, 'max_samples': 0.8, 'max_features': 'log2', 'criterion': 'entropy', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d40fa0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space['n_estimators'] = [1220, 225, 230, 240, 260]\n",
    "space['criterion'] = [\"entropy\"]\n",
    "space['min_samples_split'] = [3]\n",
    "space['max_features'] = ['sqrt', 'log2', None]\n",
    "space['n_jobs'] = [4]\n",
    "space['class_weight'] = ['balanced', 'balanced_subsample']\n",
    "space['oob_score'] = [True]\n",
    "space['max_samples'] = [0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95cd6d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8073163322443114\n",
      "Best Hyperparameters: {'oob_score': True, 'n_jobs': 4, 'n_estimators': 1220, 'min_samples_split': 3, 'max_samples': 0.9, 'max_features': 'sqrt', 'criterion': 'entropy', 'class_weight': 'balanced_subsample'}\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(model, space, n_iter=1000, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9e61d0",
   "metadata": {},
   "source": [
    "#### LGBM hyper tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f8a7114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'class_weight': None,\n",
       " 'colsample_bytree': 1.0,\n",
       " 'importance_type': 'split',\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': -1,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 0.001,\n",
       " 'min_split_gain': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1,\n",
       " 'num_leaves': 31,\n",
       " 'objective': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'silent': 'warn',\n",
       " 'subsample': 1.0,\n",
       " 'subsample_for_bin': 200000,\n",
       " 'subsample_freq': 0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGBMClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbcaf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82e8830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space['boosting_type'] = ['gbdt', 'dart', 'rf']\n",
    "space['learning_rate'] = [0.25, 0.15, 0.1, 0.05, 0.01, 0.005]\n",
    "space['n_estimators'] = [50, 60, 70, 80, 100, 200, 300]\n",
    "space['class_weight'] = [None, 'balanced']\n",
    "space['reg_alpha'] = [0.0, 0.01, 0.1, 0.2]\n",
    "space['reg_lambda'] = [0.0, 0.005, 0.01, 0.05, 0.1]\n",
    "space['n_jobs'] = [4]\n",
    "space['importance_type'] = ['split', 'gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c31b1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8111509243460355\n",
      "Best Hyperparameters: {'reg_lambda': 0.01, 'reg_alpha': 0.0, 'n_jobs': 4, 'n_estimators': 200, 'learning_rate': 0.15, 'importance_type': 'split', 'class_weight': 'balanced', 'boosting_type': 'dart'}\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(lgbm_model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0db9c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space['boosting_type'] = ['gbdt', 'dart', 'rf']\n",
    "space['learning_rate'] = [0.18, 0.17, 0.16, 0.15, 0.14, 0.13, 0.12]\n",
    "space['n_estimators'] = [180, 200, 220]\n",
    "space['class_weight'] = [None, 'balanced']\n",
    "space['reg_alpha'] = [0.0, 0.001]\n",
    "space['reg_lambda'] = [0.007, 0.01, 0.013]\n",
    "space['n_jobs'] = [4]\n",
    "space['importance_type'] = ['split', 'gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c26bc0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8122252644295419\n",
      "Best Hyperparameters: {'reg_lambda': 0.013, 'reg_alpha': 0.0, 'n_jobs': 4, 'n_estimators': 220, 'learning_rate': 0.13, 'importance_type': 'split', 'class_weight': None, 'boosting_type': 'dart'}\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(lgbm_model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8e071ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space['boosting_type'] = ['gbdt', 'dart', 'rf']\n",
    "space['learning_rate'] = [0.125, 0.13, 0.135]\n",
    "space['n_estimators'] = [220, 240, 260]\n",
    "space['class_weight'] = [None, 'balanced']\n",
    "space['reg_alpha'] = [0.0]\n",
    "space['reg_lambda'] = [0.013, 0.017, 0.02]\n",
    "space['n_jobs'] = [4]\n",
    "space['importance_type'] = ['split', 'gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e329c555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8122252644295419\n",
      "Best Hyperparameters: {'reg_lambda': 0.013, 'reg_alpha': 0.0, 'n_jobs': 4, 'n_estimators': 220, 'learning_rate': 0.13, 'importance_type': 'split', 'class_weight': None, 'boosting_type': 'dart'}\n"
     ]
    }
   ],
   "source": [
    "search = RandomizedSearchCV(lgbm_model, space, n_iter=1000, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa62ca",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a20da3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space['boosting_type'] = ['gbdt', 'dart', 'rf']\n",
    "space['learning_rate'] = np.arange(0.01, 0.3, 0.01)\n",
    "space['n_estimators'] = np.arange(20, 2000, 10)\n",
    "space['class_weight'] = [None, 'balanced']\n",
    "space['reg_alpha'] = np.arange(0.0, 0.6, 0.05)\n",
    "space['reg_lambda'] = np.arange(0.0, 0.2, 0.01)\n",
    "space['n_jobs'] = [4]\n",
    "space['importance_type'] = ['split', 'gain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41ba6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier()\n",
    "search = GridSearchCV(lgbm_model, space, scoring='accuracy', n_jobs=-1, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2dbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search.fit(X1, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810de701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a342749e",
   "metadata": {},
   "source": [
    "# Selecting Folder and Ensemble Majority Decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30457e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\ALEX\\\\Kaggle\\\\space_titanic\\\\..\\\\Spaceship Titanic\\\\ensemble8\\\\LGBM1_tuned1_rev1.csv', 'C:\\\\ALEX\\\\Kaggle\\\\space_titanic\\\\..\\\\Spaceship Titanic\\\\ensemble8\\\\majority_ensem_rev2.csv', 'C:\\\\ALEX\\\\Kaggle\\\\space_titanic\\\\..\\\\Spaceship Titanic\\\\ensemble8\\\\majority_ensem_rev3.csv', 'C:\\\\ALEX\\\\Kaggle\\\\space_titanic\\\\..\\\\Spaceship Titanic\\\\ensemble8\\\\majority_ensem_rev5.csv', 'C:\\\\ALEX\\\\Kaggle\\\\space_titanic\\\\..\\\\Spaceship Titanic\\\\ensemble8\\\\majority_ensem_rev6.csv', 'C:\\\\ALEX\\\\Kaggle\\\\space_titanic\\\\..\\\\Spaceship Titanic\\\\ensemble8\\\\majority_ensem_rev7.csv']\n"
     ]
    }
   ],
   "source": [
    "rev = '8'\n",
    "en_path = '..\\\\Spaceship Titanic\\\\ensemble' + rev\n",
    "out_file_path = '..\\\\Spaceship Titanic\\\\majority_ensem_rev' + rev +'.csv'\n",
    "\n",
    "dpath = os.path.join(os.getcwd(), en_path)\n",
    "files1 = os.listdir(dpath)\n",
    "files2 = [os.path.join(dpath, f) for f in files1]\n",
    "files_e = [f for f in files2 if os.path.isfile(f)]\n",
    "print(files_e)\n",
    "\n",
    "fnam = [fn.rsplit(\"\\\\\")[-1].split(\".\")[0] for fn in files_e]\n",
    "dfe = None\n",
    "for (file,m_name) in zip(files_e,fnam):\n",
    "    df = pd.read_csv(file)\n",
    "    if dfe is None:\n",
    "        dfe = df\n",
    "        dfe = dfe.rename(columns={\"Transported\": m_name})\n",
    "    else:\n",
    "        dfe[m_name] = df['Transported'].values\n",
    "\n",
    "dfe_sum = dfe.sum(axis=1)\n",
    "dfe_cnt = dfe.count(axis=1)\n",
    "dfe['sum'] = dfe_sum\n",
    "dfe['count'] = dfe_cnt\n",
    "dfe['Transported'] = 2 * dfe['sum'] >= dfe['count']\n",
    "dfe_f = dfe[['PassengerId', 'Transported']]\n",
    "dfe_f.to_csv(out_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879afec",
   "metadata": {},
   "source": [
    "# Stacking Ensemble\n",
    "### Hyper parameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1904667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1, df_id = get_train_data_transform_rev1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad053504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:39:15] WARNING: C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-08de971ced8a8cdc6-1/xgboost/xgboost-ci-windows/src/learner.cc:767: \n",
      "Parameters: { \"grow_policy\" } are not used.\n",
      "\n",
      "Best Score: 0.7923988025166548\n",
      "Best Hyperparameters: {'n_jobs': 2, 'n_estimators': 400, 'learning_rate': 0.1, 'grow_policy': 0, 'booster': 'gblinear'}\n"
     ]
    }
   ],
   "source": [
    "tune_model = XGBClassifier()\n",
    "\n",
    "space = dict()\n",
    "space['n_estimators'] = [100, 200, 400, 800]\n",
    "space['learning_rate'] = [0.15, 0.1, 0.05, 0.01]\n",
    "space['booster'] = ['gbtree', 'gblinear', 'dart']\n",
    "space['n_jobs'] = [2]\n",
    "\n",
    "search = RandomizedSearchCV(tune_model, space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fa09cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8041719243945348\n",
      "Best Hyperparameters: {'n_jobs': 2, 'n_estimators': 300, 'learning_rate': 0.08, 'booster': 'gbtree'}\n"
     ]
    }
   ],
   "source": [
    "tune_model = XGBClassifier()\n",
    "\n",
    "space = dict()\n",
    "space['n_estimators'] = [300, 400, 500]\n",
    "space['learning_rate'] = [0.13, 0.1, 0.08]\n",
    "space['booster'] = ['gbtree', 'gblinear', 'dart']\n",
    "space['n_jobs'] = [2]\n",
    "\n",
    "search = RandomizedSearchCV(tune_model, space, n_iter=27, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87af6a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7944307324665246\n",
      "Best Hyperparameters: {'n_estimators': 100, 'learning_rate': 0.75, 'algorithm': 'SAMME.R'}\n"
     ]
    }
   ],
   "source": [
    "tune_model = AdaBoostClassifier()\n",
    "\n",
    "space = dict()\n",
    "space['n_estimators'] = [100, 300, 500]\n",
    "space['learning_rate'] = [1.0, 0.75, 0.5]\n",
    "space['algorithm'] = ['SAMME', 'SAMME.R']\n",
    "# space['n_jobs'] = [2]\n",
    "\n",
    "search = RandomizedSearchCV(tune_model, space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec5b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_model = ExtraTreesClassifier()\n",
    "\n",
    "space = dict()\n",
    "space['n_estimators'] = [450, 500, 650, 800]\n",
    "space['criterion'] = ['gini', 'entropy', 'log_loss']\n",
    "space['max_features'] = ['sqrt', 'log2', None]\n",
    "space['bootstrap'] = [False, True]\n",
    "space['n_jobs'] = [2]\n",
    "\n",
    "search = RandomizedSearchCV(tune_model, space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ce33224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8008362542932601\n",
      "Best Hyperparameters: {'n_jobs': 2, 'n_estimators': 500, 'bootstrap_features': True, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "tune_model = BaggingClassifier()\n",
    "\n",
    "space = dict()\n",
    "space['n_estimators'] = [100, 300, 500]\n",
    "space['bootstrap'] = [False, True]\n",
    "space['bootstrap_features'] = [False, True]\n",
    "space['n_jobs'] = [2]\n",
    "\n",
    "search = RandomizedSearchCV(tune_model, space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a860a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7619148270130374\n",
      "Best Hyperparameters: {'weights': 'uniform', 'p': 1, 'n_neighbors': 24, 'n_jobs': 2, 'algorithm': 'kd_tree'}\n"
     ]
    }
   ],
   "source": [
    "tune_model = KNeighborsClassifier()\n",
    "\n",
    "space = dict()\n",
    "space['n_neighbors'] = [3, 5, 8, 12, 18, 24]\n",
    "space['weights'] = ['uniform', 'distance']\n",
    "space['algorithm'] = ['ball_tree', 'kd_tree', 'brute']\n",
    "space['p'] = [1, 2, 3]\n",
    "space['n_jobs'] = [2]\n",
    "\n",
    "search = RandomizedSearchCV(tune_model, space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8ac78cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7646379552839613\n",
      "Best Hyperparameters: {'penalty': 'l2', 'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "tune_model = LogisticRegression()\n",
    "\n",
    "space = dict()\n",
    "space['penalty'] = ['l1', 'l2', 'elasticnet', None]\n",
    "space['max_iter'] = [100, 200, 300]\n",
    "# space['n_jobs'] = [2]\n",
    "\n",
    "search = RandomizedSearchCV(tune_model, space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "result = search.fit(X1, Y1)\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdf52b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ba81d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_models = dict()\n",
    "en_models['XGBClassifier'] = XGBClassifier(n_estimators=300, learning_rate=0.08, booster='gbtree')\n",
    "\n",
    "en_models['LGBMClassifier'] = LGBMClassifier(reg_lambda=0.013, reg_alpha=0.0, n_estimators=220, learning_rate=0.13, \n",
    "                                            importance_type='split', class_weight=None, boosting_type='dart')\n",
    "\n",
    "en_models['RandomForestClassifier'] = RandomForestClassifier(oob_score=True, n_estimators=1220, min_samples_split=3, \n",
    "                                                            max_samples=0.9, max_features='sqrt', criterion='entropy', \n",
    "                                                            class_weight='balanced_subsample')\n",
    "\n",
    "en_models['AdaBoostClassifier'] = AdaBoostClassifier(n_estimators=100, learning_rate=0.75, algorithm='SAMME.R')\n",
    "\n",
    "en_models['ExtraTreesClassifier'] = ExtraTreesClassifier(n_estimators=500, max_features=None, criterion='entropy', bootstrap=True)\n",
    "\n",
    "en_models['BaggingClassifier'] = BaggingClassifier(n_estimators=500, bootstrap_features=True, bootstrap=True)\n",
    "\n",
    "# en_models['KNeighborsClassifier'] = KNeighborsClassifier(weights='uniform', p=1, n_neighbors=24, algorithm='kd_tree')\n",
    "\n",
    "# en_models['LogisticRegression'] = LogisticRegression(penalty='l2', max_iter=100)\n",
    "\n",
    "# en_models['NN'] = nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a8a8c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, names = list(), list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "494da7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">XGBClassifier 0.804 (0.010)\n",
      ">LGBMClassifier 0.812 (0.009)\n",
      ">RandomForestClassifier 0.806 (0.011)\n",
      ">AdaBoostClassifier 0.794 (0.012)\n",
      ">ExtraTreesClassifier 0.805 (0.011)\n",
      ">BaggingClassifier 0.802 (0.012)\n",
      ">KNeighborsClassifier 0.762 (0.011)\n",
      ">LogisticRegression 0.765 (0.012)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<keras.engine.sequential.Sequential object at 0x0000019838C86100>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m                 \u001b[0mtasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14832/506340976.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0men_models\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'>%s %.3f (%.3f)'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14832/1006756642.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model, X, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRepeatedStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    248\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    249\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 250\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    252\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    831\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                 \u001b[0mislice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m     results = parallel(\n\u001b[0;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m--> 252\u001b[1;33m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    253\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_64bit\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                 \"scikit-learn estimator instead of a class.\")\n\u001b[0;32m     66\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 raise TypeError(\"Cannot clone object '%s' (type %s): \"\n\u001b[0m\u001b[0;32m     68\u001b[0m                                 \u001b[1;34m\"it does not seem to be a scikit-learn \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                                 \u001b[1;34m\"estimator as it does not implement a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot clone object '<keras.engine.sequential.Sequential object at 0x0000019838C86100>' (type <class 'keras.engine.sequential.Sequential'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "for name, model in en_models.items():\n",
    "    scores = evaluate_model(model, X1, Y1)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "299e2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f48dca56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e041e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8673dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the base models\n",
    "level0 = [(name, model) for name, model in en_models.items()]\n",
    "# define meta learner model\n",
    "level1 = LogisticRegression()\n",
    "# define the stacking ensemble\n",
    "model_lvl = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "793efccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('XGBClassifier',\n",
       "                                XGBClassifier(base_score=None, booster='gbtree',\n",
       "                                              callbacks=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              early_stopping_rounds=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric=None,\n",
       "                                              feature_types=None, gamma=None,\n",
       "                                              gpu_id=None, grow_policy=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constra...\n",
       "                                                       n_estimators=1220,\n",
       "                                                       oob_score=True)),\n",
       "                               ('AdaBoostClassifier',\n",
       "                                AdaBoostClassifier(learning_rate=0.75,\n",
       "                                                   n_estimators=100)),\n",
       "                               ('ExtraTreesClassifier',\n",
       "                                ExtraTreesClassifier(bootstrap=True,\n",
       "                                                     criterion='entropy',\n",
       "                                                     max_features=None,\n",
       "                                                     n_estimators=500)),\n",
       "                               ('BaggingClassifier',\n",
       "                                BaggingClassifier(bootstrap_features=True,\n",
       "                                                  n_estimators=500))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lvl.fit(X1, Y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f01a86dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_t, df_id = get_test_data_transform_rev1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f9354b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_t = model_lvl.predict(X1_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31fcd5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(data=Y1_t, columns=['Transported'])\n",
    "pred_df['Transported'] = pred_df['Transported'].astype(bool)\n",
    "df_test = pd.concat([df_id, pred_df], axis=1)\n",
    "df_test.to_csv('..\\\\Spaceship Titanic\\\\ensemble_stack_rev2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6cd5be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbaf8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d41def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46b720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285b9b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
